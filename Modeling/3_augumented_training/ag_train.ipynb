{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 42\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m augmented_team_stats, augmented_player_stats, augmented_ball_stats\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Augment the dataset\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m train_team_stats, train_player_stats, train_ball_stats \u001b[38;5;241m=\u001b[39m augment_data(\u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m, train_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mplayer_stats\u001b[39m\u001b[38;5;124m'\u001b[39m], train_dataset[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mball_stats\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\chavv\\anaconda\\envs\\huggingface-torch\\lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc, accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize Weights & Biases\n",
    "wandb.init(project=\"T20I\")\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "from model_utils import collate_fn_with_padding, extract_data, augment_match_data, CricketDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Load the Datasets\n",
    "train_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'train_dataset.pkl'), 'rb'))\n",
    "val_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'val_dataset.pkl'), 'rb'))\n",
    "test_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'test_dataset.pkl'), 'rb'))\n",
    "\n",
    "# Step 1: Extract Data from Dataset\n",
    "train_team_data, train_player_data, train_ball_data, train_labels = extract_data(train_dataset)\n",
    "val_team_data, val_player_data, val_ball_data, val_labels = extract_data(val_dataset)\n",
    "test_team_data, test_player_data, test_ball_data, test_labels = extract_data(test_dataset)\n",
    "\n",
    "# Step 2: Augment Data\n",
    "train_ball_data, train_team_data, train_player_data, train_labels = augment_match_data(train_ball_data, train_team_data, train_player_data, train_labels)\n",
    "val_ball_data, val_team_data, val_player_data, val_labels = augment_match_data(val_ball_data, val_team_data, val_player_data, val_labels)\n",
    "test_ball_data, test_team_data, test_player_data, test_labels = augment_match_data(test_ball_data, test_team_data, test_player_data, test_labels)\n",
    "\n",
    "# Step 3: Convert augmented data to PyTorch Dataset\n",
    "train_dataset = CricketDataset(train_team_data, train_player_data, train_ball_data, train_labels)\n",
    "val_dataset = CricketDataset(val_team_data, val_player_data, val_ball_data, val_labels)\n",
    "test_dataset = CricketDataset(test_team_data, test_player_data, test_ball_data, test_labels) \n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn_with_padding)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn_with_padding)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn_with_padding)\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Step 3: Define Model\n",
    "class TeamEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout=0.5):\n",
    "        super(TeamEncoder, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class PlayerEncoder(nn.Module):\n",
    "    def __init__(self, input_channels, hidden_size, dropout=0.5):\n",
    "        super(PlayerEncoder, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(input_channels, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)  # Ensure input tensor is on the same device\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.view(x.size(0), -1)  # Flatten the tensor\n",
    "        if not hasattr(self, 'fc1'):\n",
    "            self.fc1 = nn.Linear(x.size(1), self.hidden_size).to(device)  # Ensure fc1 is on the same device\n",
    "        x = self.fc1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class BallEncoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, dropout=0.5):\n",
    "        super(BallEncoder, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.rnn = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, (hidden, _) = self.rnn(x, (h0, c0))\n",
    "        hidden = self.dropout(hidden)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, input_size, num_classes, dropout=0.5):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "class EncoderDecoderModel(nn.Module):\n",
    "    def __init__(self, team_input_size, player_input_channels, ball_input_size, hidden_size, num_layers, num_classes, dropout=0.5):\n",
    "        super(EncoderDecoderModel, self).__init__()\n",
    "        self.team_encoder = TeamEncoder(team_input_size, hidden_size, dropout)\n",
    "        self.player_encoder = PlayerEncoder(player_input_channels, hidden_size, dropout)\n",
    "        self.ball_encoder = BallEncoder(ball_input_size, hidden_size, num_layers, dropout)\n",
    "        self.decoder = Decoder(hidden_size * 3, num_classes, dropout)\n",
    "\n",
    "    def forward(self, team, player, ball):\n",
    "        team = team.float()\n",
    "        player = player.float()\n",
    "        ball = ball.float()\n",
    "\n",
    "        team_hidden = self.team_encoder(team)\n",
    "\n",
    "        if player.dim() == 3:\n",
    "            player = player.unsqueeze(1)  # Add channel dimension\n",
    "        player_hidden = self.player_encoder(player)\n",
    "\n",
    "        if ball.dim() == 2:\n",
    "            ball = ball.unsqueeze(1)\n",
    "        ball_hidden = self.ball_encoder(ball)[-1]\n",
    "\n",
    "        combined_hidden = torch.cat((team_hidden, player_hidden, ball_hidden), dim=1)\n",
    "        output = self.decoder(combined_hidden)\n",
    "        return output\n",
    "\n",
    "model = EncoderDecoderModel(\n",
    "    team_input_size=train_team_data[0].shape[0],\n",
    "    player_input_channels=1,  # Assuming player data is 2D and needs a channel dimension\n",
    "    ball_input_size=train_ball_data[0].shape[1],\n",
    "    hidden_size=64,\n",
    "    num_layers=2,\n",
    "    num_classes=1,\n",
    "    dropout=0.5\n",
    ").to(device)  # Move model to device\n",
    "print(f\"Team input size: {train_team_data[0].shape[0]}\")\n",
    "print(f\"ball input size: {train_ball_data[0].shape[1]}\")\n",
    "print(f\"Player input size: {train_player_data[0].shape}\")\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)  # L2 regularization\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=15, verbose=True)\n",
    "\n",
    "# Define the directory to save the best model and plots\n",
    "save_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "\n",
    "# Step 4: Train Model\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "num_epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    for team, player, ball, labels in tqdm(train_dataloader):\n",
    "        team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "        labels = labels.float()\n",
    "        outputs = model(team, player, ball)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        running_corrects += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = 100 * running_corrects / total\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for team, player, ball, labels in val_dataloader:\n",
    "            team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "            labels = labels.float()\n",
    "            outputs = model(team, player, ball)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs.data > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_corrects += (predicted == labels).sum().item()\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {train_acc:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Log metrics to Weights & Biases\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": avg_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        trigger_times = 0\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))\n",
    "        # Save model checkpoint to Weights & Biases\n",
    "        wandb.save(os.path.join(save_dir, 'best_model.pth'))\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtrain_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mteam_stats\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m:\n\u001b[0;32m      2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i)\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\chavv\\anaconda\\envs\\huggingface-torch\\lib\\site-packages\\torch\\utils\\data\\dataset.py:412\u001b[0m, in \u001b[0;36mSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(idx, \u001b[38;5;28mlist\u001b[39m):\n\u001b[0;32m    411\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[i] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m idx]]\n\u001b[1;32m--> 412\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m]\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 5: Plot Training History\n",
    "epochs_range = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, train_losses, label='Training Loss')\n",
    "plt.plot(epochs_range, val_losses, label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss History')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, train_accuracies, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_accuracies, label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.title('Accuracy History')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(save_dir, 'training_history.png'))\n",
    "plt.show()\n",
    "\n",
    "# Log final plots to Weights & Biases\n",
    "wandb.log({\"training_history\": wandb.Image(os.path.join(save_dir, 'training_history.png'))})\n",
    "\n",
    "# Step 6: Evaluate Model on Test Data\n",
    "model.load_state_dict(torch.load(os.path.join(save_dir, 'best_model.pth')))\n",
    "model.to(device)  # Move model to device\n",
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probs = []\n",
    "\n",
    "# Define window sizes\n",
    "window_sizes = [20,25,30,35,40,45]\n",
    "stage_metrics = {}\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for team, player, ball, labels in test_dataloader:\n",
    "        team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "        team = team.float()\n",
    "        player = player.float()\n",
    "        ball = ball.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        outputs = model(team, player, ball)\n",
    "        probs = outputs.squeeze().cpu().numpy()\n",
    "        if probs.ndim == 0:\n",
    "            probs = probs.reshape(1)  # Convert scalar to 1D array\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_probs.extend(probs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Test Accuracy: {:.2f} %'.format(100 * correct / total))\n",
    "\n",
    "    # Calculate metrics for each window size\n",
    "    for window in window_sizes:\n",
    "        window_length = window * 6  # Convert overs to balls\n",
    "        if len(all_labels) >= window_length:\n",
    "            window_labels = all_labels[:window_length]\n",
    "            window_predictions = all_predictions[:window_length]\n",
    "        else:\n",
    "            window_labels = all_labels\n",
    "            window_predictions = all_predictions\n",
    "\n",
    "        accuracy = accuracy_score(window_labels, window_predictions)\n",
    "        precision = precision_score(window_labels, window_predictions)\n",
    "        recall = recall_score(window_labels, window_predictions)\n",
    "        f1 = f1_score(window_labels, window_predictions)\n",
    "        stage_metrics[f\"{window} overs\"] = {\n",
    "            \"accuracy\": accuracy,\n",
    "            \"precision\": precision,\n",
    "            \"recall\": recall,\n",
    "            \"f1\": f1\n",
    "        }\n",
    "\n",
    "# Calculate overall metrics\n",
    "overall_accuracy = accuracy_score(all_labels, all_predictions)\n",
    "overall_precision = precision_score(all_labels, all_predictions)\n",
    "overall_recall = recall_score(all_labels, all_predictions)\n",
    "overall_f1 = f1_score(all_labels, all_predictions)\n",
    "\n",
    "overall_metrics = {\n",
    "    \"accuracy\": overall_accuracy,\n",
    "    \"precision\": overall_precision,\n",
    "    \"recall\": overall_recall,\n",
    "    \"f1\": overall_f1\n",
    "}\n",
    "\n",
    "metrics = {\n",
    "    \"stage_metrics\": stage_metrics,\n",
    "    \"overall_metrics\": overall_metrics\n",
    "}\n",
    "\n",
    "print(metrics)\n",
    "\n",
    "# Step 7: Generate Evaluation Metrics\n",
    "conf_matrix = confusion_matrix(all_labels, all_predictions)\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix)\n",
    "\n",
    "class_report = classification_report(all_labels, all_predictions, target_names=['Class 0', 'Class 1'])\n",
    "print('Classification Report:')\n",
    "print(class_report)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(all_labels, all_probs)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc))\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.savefig(os.path.join(save_dir, 'roc_curve.png'))\n",
    "plt.show()\n",
    "\n",
    "# Convert confusion matrix to DataFrame for logging\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=['Actual Class 0', 'Actual Class 1'], columns=['Predicted Class 0', 'Predicted Class 1'])\n",
    "\n",
    "# Log evaluation metrics to Weights & Biases\n",
    "wandb.log({\n",
    "    \"confusion_matrix\": wandb.Table(dataframe=conf_matrix_df),\n",
    "    \"classification_report\": class_report,\n",
    "    \"stage_metrics\": stage_metrics,\n",
    "    \"overall_metrics\": overall_metrics\n",
    "})\n",
    "\n",
    "# Finish the Weights & Biases run\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the models\n",
    "class TeamStatsModel(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(TeamStatsModel, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm1d(32),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class PlayerStatsModel(nn.Module):\n",
    "    def __init__(self, input_size, seq_len):\n",
    "        super(PlayerStatsModel, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_size, out_channels=32, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool1 = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=3)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.pool2 = nn.MaxPool1d(2)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc = nn.Linear(64 * ((seq_len - 4) // 4), 16)  # Adjust input size dynamically\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # Convert to (batch, channels, seq_len)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class BallToBallModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(BallToBallModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_dim, 128, batch_first=True, bidirectional=False)  # Not bidirectional\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(128, 16)  # Adjust input size to 128\n",
    "\n",
    "    def forward(self, x, lengths):\n",
    "        # Pack the sequences\n",
    "        x_packed = nn.utils.rnn.pack_padded_sequence(x, lengths, batch_first=True, enforce_sorted=False)\n",
    "        output_packed, (hn, cn) = self.lstm(x_packed)\n",
    "        # Use the final hidden state directly\n",
    "        hn = hn[-1,:,:]\n",
    "        x = self.dropout(hn)\n",
    "        x = F.relu(self.fc(x))\n",
    "        return x\n",
    "\n",
    "class CombinedModel(nn.Module):\n",
    "    def __init__(self, team_input_size, player_input_size, player_seq_len, ball_input_dim):\n",
    "        super(CombinedModel, self).__init__()\n",
    "        self.team_model = TeamStatsModel(team_input_size)\n",
    "        self.player_model = PlayerStatsModel(player_input_size, player_seq_len)\n",
    "        self.ball_model = BallToBallModel(ball_input_dim)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(16+16+16, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(32, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, team_input, player_input, ball_input, ball_lengths):\n",
    "        team_output = self.team_model(team_input)\n",
    "        player_output = self.player_model(player_input)\n",
    "        ball_output = self.ball_model(ball_input, ball_lengths)\n",
    "        combined = torch.cat((team_output, player_output, ball_output), dim=1)\n",
    "        output = self.fc(combined)\n",
    "        return output.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0235, Test Accuracy: 0.9893\n"
     ]
    }
   ],
   "source": [
    "# Check if GPU is available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Initialize the model\n",
    "team_input_size = test_dataloader.dataset[0][0].shape[0]\n",
    "player_input_size = test_dataloader.dataset[0][1].shape[1]\n",
    "player_seq_len = test_dataloader.dataset[0][1].shape[0]  # Sequence length for player stats\n",
    "ball_input_dim = test_dataloader.dataset[0][2].shape[1]\n",
    "\n",
    "# Initialize the model\n",
    "model = CombinedModel(team_input_size, player_input_size, player_seq_len, ball_input_dim).to(device)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# Load the t20i model weights\n",
    "model.load_state_dict(torch.load('../2_naivetraining/t20i.pth',weights_only=True))\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "test_correct_predictions = 0\n",
    "test_total_predictions = 0\n",
    "test_running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for team_input, player_input, ball_input, labels, ball_lengths in test_dataloader:\n",
    "        team_input, player_input, ball_input, labels = team_input.to(device), player_input.to(device), ball_input.to(device), labels.to(device)\n",
    "        outputs = model(team_input, player_input, ball_input, ball_lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        test_correct_predictions += (predictions == labels).sum().item()\n",
    "        test_total_predictions += labels.size(0)\n",
    "\n",
    "test_avg_loss = test_running_loss / len(test_dataloader)\n",
    "test_accuracy = test_correct_predictions / test_total_predictions\n",
    "print(f\"Test Loss: {test_avg_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      4478\n",
      "         1.0       1.00      0.98      0.99      4497\n",
      "\n",
      "    accuracy                           0.99      8975\n",
      "   macro avg       0.99      0.99      0.99      8975\n",
      "weighted avg       0.99      0.99      0.99      8975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Get the predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for team_input, player_input, ball_input, labels, ball_lengths in test_dataloader:\n",
    "        team_input, player_input, ball_input, labels = team_input.to(device), player_input.to(device), ball_input.to(device), labels.to(device)\n",
    "        outputs = model(team_input, player_input, ball_input, ball_lengths)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0236, Test Accuracy: 0.9889\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99      4478\n",
      "         1.0       1.00      0.98      0.99      4497\n",
      "\n",
      "    accuracy                           0.99      8975\n",
      "   macro avg       0.99      0.99      0.99      8975\n",
      "weighted avg       0.99      0.99      0.99      8975\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filter test data to take only the first 10 overs\n",
    "test_dataloader.dataset.ball_stats_list = [ball_stats[:20] for ball_stats in test_dataloader.dataset.ball_stats_list]\n",
    "\n",
    "# Testing\n",
    "model.eval()\n",
    "test_correct_predictions = 0\n",
    "test_total_predictions = 0\n",
    "test_running_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for team_input, player_input, ball_input, labels, ball_lengths in test_dataloader:\n",
    "        team_input, player_input, ball_input, labels = team_input.to(device), player_input.to(device), ball_input.to(device), labels.to(device)\n",
    "        outputs = model(team_input, player_input, ball_input, ball_lengths)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        test_correct_predictions += (predictions == labels).sum().item()\n",
    "        test_total_predictions += labels.size(0)\n",
    "\n",
    "test_avg_loss = test_running_loss / len(test_dataloader)\n",
    "test_accuracy = test_correct_predictions / test_total_predictions\n",
    "print(f\"Test Loss: {test_avg_loss:.4f}, Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Get the predictions and ground truth labels\n",
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for team_input, player_input, ball_input, labels, ball_lengths in test_dataloader:\n",
    "        team_input, player_input, ball_input, labels = team_input.to(device), player_input.to(device), ball_input.to(device), labels.to(device)\n",
    "        outputs = model(team_input, player_input, ball_input, ball_lengths)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_labels = np.array(all_labels)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(all_labels, all_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
