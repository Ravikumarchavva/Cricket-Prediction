{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Player profiles and IDs have been added to the CSV.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chavv\\anaconda\\envs\\scrappper\\lib\\functools.py:888: DataOrientationWarning: Row orientation inferred during DataFrame construction. Explicitly specify the orientation by passing `orient=\"row\"` to silence this warning.\n",
      "  return dispatch(args[0].__class__)(*args, **kw)\n"
     ]
    }
   ],
   "source": [
    "import polars as pl\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "\n",
    "# Function to extract player profile URL and ID\n",
    "def get_player_profile(player_name):\n",
    "    search_name = player_name.replace(\" \", \"%20\")  # URL-encode the player name\n",
    "    search_url = f\"https://search.espncricinfo.com/ci/content/site/search.html?search={search_name}\"\n",
    "    headers = {\n",
    "        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(search_url, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "        # Find the first player profile link\n",
    "        player_links = soup.find_all(\"a\", href=True)\n",
    "        for link in player_links:\n",
    "            if \"/cricketers/\" in link[\"href\"]:\n",
    "                profile_url = f\"https://www.espncricinfo.com{link['href']}\"\n",
    "                player_id = profile_url.split(\"-\")[-1]  # Extract player ID from URL\n",
    "                return player_name, profile_url, player_id\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching {player_name}: {e}\")\n",
    "    \n",
    "    return player_name, \"Not found\", \"Not found\"\n",
    "\n",
    "# Load the CSV with player names into a Polars DataFrame\n",
    "df = pl.read_csv(\"player_names.csv\")  # Assuming the CSV has a 'Player' column\n",
    "\n",
    "df = df[:20]\n",
    "# Add new columns for profile URL and player ID\n",
    "df = df.with_columns([\n",
    "    pl.lit(\"\").alias(\"profile_url\"),\n",
    "    pl.lit(\"\").alias(\"player_id\")\n",
    "])\n",
    "\n",
    "# Define a function to process the DataFrame in parallel batches\n",
    "def process_in_batches(player_names, batch_size=10):\n",
    "    results = []\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=batch_size) as executor:\n",
    "        # Submit each player search task to the thread pool\n",
    "        future_to_player = {executor.submit(get_player_profile, player_name): player_name for player_name in player_names}\n",
    "        \n",
    "        # Process the completed tasks as they finish\n",
    "        for future in as_completed(future_to_player):\n",
    "            try:\n",
    "                result = future.result()\n",
    "                results.append(result)\n",
    "            except Exception as e:\n",
    "                print(f\"Error in future: {e}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Batch size for processing requests in parallel\n",
    "batch_size = 10  # Adjust batch size according to your system capabilities\n",
    "\n",
    "# Get player names from the DataFrame\n",
    "player_names = df['Player'].to_list()\n",
    "\n",
    "# Process player names in parallel and get results\n",
    "parallel_results = process_in_batches(player_names, batch_size=batch_size)\n",
    "\n",
    "# Convert the parallel results back to a Polars DataFrame\n",
    "updated_df = pl.DataFrame(parallel_results, schema=[\"Player\", \"profile_url\", \"player_id\"])\n",
    "\n",
    "# Save the updated DataFrame back to a CSV file\n",
    "updated_df.write_csv(\"players_with_ids_20.csv\")\n",
    "\n",
    "print(\"Player profiles and IDs have been added to the CSV.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 1)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>Player</th></tr><tr><td>str</td></tr></thead><tbody><tr><td>&quot;Parvez Rasool&quot;</td></tr><tr><td>&quot;M Shumba&quot;</td></tr><tr><td>&quot;Mominul Haque&quot;</td></tr><tr><td>&quot;DI Allan&quot;</td></tr><tr><td>&quot;Mohammad Naim&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 1)\n",
       "┌───────────────┐\n",
       "│ Player        │\n",
       "│ ---           │\n",
       "│ str           │\n",
       "╞═══════════════╡\n",
       "│ Parvez Rasool │\n",
       "│ M Shumba      │\n",
       "│ Mominul Haque │\n",
       "│ DI Allan      │\n",
       "│ Mohammad Naim │\n",
       "└───────────────┘"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scrappper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
