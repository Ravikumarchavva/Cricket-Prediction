{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best run bumbling-sweep-2 with 80.2588996763754% validation accuracy\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr': 0.001,\n",
       " 'dropout': 0.6440042563772401,\n",
       " 'save_dir': 'D:\\\\github\\\\Cricket-Prediction\\\\ml_modeling\\\\4_hptuning',\n",
       " 'gpu_count': 1,\n",
       " 'batch_size': 8,\n",
       " 'num_epochs': 50,\n",
       " 'num_layers': 2,\n",
       " 'hidden_size': 128,\n",
       " 'enable_plots': False,\n",
       " 'weight_decay': 4.112676091367997e-05,\n",
       " 'learning_rate': 0.0009586290162506808,\n",
       " 'torch_version': '2.4.1',\n",
       " 'cuda_available': True,\n",
       " 'python_version': '3.9.20 (main, Oct  3 2024, 07:38:01) [MSC v.1929 64 bit (AMD64)]'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "import os\n",
    "api = wandb.Api()\n",
    "\n",
    "sweep = api.sweep(\"ravikumarchavva-org/T20I-Cricket-Win-Prediction/xpxta7kj\")\n",
    "runs = sorted(sweep.runs,\n",
    "  key=lambda run: run.summary.get(\"val_accuracy\", 0), reverse=True)\n",
    "val_acc = runs[0].summary.get(\"val_accuracy\", 0)\n",
    "print(f\"Best run {runs[0].name} with {val_acc}% validation accuracy\")\n",
    "\n",
    "config = runs[0].config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: ravikumarchavva (ravikumarchavva-org). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\github\\Cricket-Prediction\\Modeling\\5_selecting_best_model\\wandb\\run-20241122_171600-9xfd5c20</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction/runs/9xfd5c20' target=\"_blank\">clean-waterfall-61</a></strong> to <a href='https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction' target=\"_blank\">https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction/runs/9xfd5c20' target=\"_blank\">https://wandb.ai/ravikumarchavva-org/T20I-Cricket-Win-Prediction/runs/9xfd5c20</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb:   1 of 1 files downloaded.  \n"
     ]
    }
   ],
   "source": [
    "wandb.init(project=\"T20I-Cricket-Win-Prediction\", job_type=\"inference\")\n",
    "\n",
    "# Use the artifact name as logged during training\n",
    "artifact = wandb.use_artifact('T20I-Cricket-Win-Prediction/best_model:latest', type='model')  # Replace 'your_entity' with your WandB username or team name\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(),\"..\"))\n",
    "\n",
    "from model_utils import CricketDataset, collate_fn_with_padding, extract_data, augment_match_data\n",
    "from torch.utils.data import DataLoader\n",
    "import pickle\n",
    "\n",
    "# Load the Datasets\n",
    "train_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'train_dataset.pkl'), 'rb'))\n",
    "val_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'val_dataset.pkl'), 'rb'))\n",
    "test_dataset = pickle.load(open(os.path.join(os.getcwd(), '..', \"data\", \"pytorch_data\", 'test_dataset.pkl'), 'rb'))\n",
    "\n",
    "# Step 1: Extract Data from Dataset\n",
    "train_team_data, train_player_data, train_ball_data, train_labels = extract_data(train_dataset)\n",
    "val_team_data, val_player_data, val_ball_data, val_labels = extract_data(val_dataset)\n",
    "test_team_data, test_player_data, test_ball_data, test_labels = extract_data(test_dataset)\n",
    "\n",
    "# Step 2: Augment Data\n",
    "train_ball_data, train_team_data, train_player_data, train_labels = augment_match_data(train_ball_data, train_team_data, train_player_data, train_labels)\n",
    "val_ball_data, val_team_data, val_player_data, val_labels = augment_match_data(val_ball_data, val_team_data, val_player_data, val_labels)\n",
    "test_ball_data, test_team_data, test_player_data, test_labels = augment_match_data(test_ball_data, test_team_data, test_player_data, test_labels)\n",
    "\n",
    "# Step 3: Convert augmented data to PyTorch Dataset\n",
    "train_dataset = CricketDataset(train_team_data, train_player_data, train_ball_data, train_labels)\n",
    "val_dataset = CricketDataset(val_team_data, val_player_data, val_ball_data, val_labels)\n",
    "test_dataset = CricketDataset(test_team_data, test_player_data, test_ball_data, test_labels) \n",
    "\n",
    "# Step 4: Create DataLoaders\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_with_padding)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=8, shuffle=True, collate_fn=collate_fn_with_padding)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=8, shuffle=False, collate_fn=collate_fn_with_padding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\chavv\\anaconda\\envs\\huggingface-torch\\lib\\site-packages\\torch\\nn\\modules\\rnn.py:88: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5631325927251238 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for EncoderDecoderModel:\n\tUnexpected key(s) in state_dict: \"player_encoder.fc1.weight\", \"player_encoder.fc1.bias\", \"ball_encoder.rnn.weight_ih_l1\", \"ball_encoder.rnn.weight_hh_l1\", \"ball_encoder.rnn.bias_ih_l1\", \"ball_encoder.rnn.bias_hh_l1\". \n\tsize mismatch for team_encoder.fc1.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([128, 13]).\n\tsize mismatch for team_encoder.fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for ball_encoder.rnn.weight_ih_l0: copying a param with shape torch.Size([1024, 10]) from checkpoint, the shape in current model is torch.Size([512, 10]).\n\tsize mismatch for ball_encoder.rnn.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for ball_encoder.rnn.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for ball_encoder.rnn.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([1, 384]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 18\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodel_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m  EncoderDecoderModel\n\u001b[0;32m      7\u001b[0m model \u001b[38;5;241m=\u001b[39m EncoderDecoderModel(\n\u001b[0;32m      8\u001b[0m     team_input_size\u001b[38;5;241m=\u001b[39mtrain_team_data[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m      9\u001b[0m     player_input_channels\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \u001b[38;5;66;03m# Assuming player data is 2D and needs a channel dimension\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     14\u001b[0m     dropout\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.5631325927251238\u001b[39m\n\u001b[0;32m     15\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move model to device\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43martifact_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mbest_model.pth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\chavv\\anaconda\\envs\\huggingface-torch\\lib\\site-packages\\torch\\nn\\modules\\module.py:2215\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[0;32m   2210\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2211\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2212\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2214\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2215\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2216\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2217\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for EncoderDecoderModel:\n\tUnexpected key(s) in state_dict: \"player_encoder.fc1.weight\", \"player_encoder.fc1.bias\", \"ball_encoder.rnn.weight_ih_l1\", \"ball_encoder.rnn.weight_hh_l1\", \"ball_encoder.rnn.bias_ih_l1\", \"ball_encoder.rnn.bias_hh_l1\". \n\tsize mismatch for team_encoder.fc1.weight: copying a param with shape torch.Size([256, 13]) from checkpoint, the shape in current model is torch.Size([128, 13]).\n\tsize mismatch for team_encoder.fc1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.weight: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.running_mean: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for team_encoder.batch_norm1.running_var: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for ball_encoder.rnn.weight_ih_l0: copying a param with shape torch.Size([1024, 10]) from checkpoint, the shape in current model is torch.Size([512, 10]).\n\tsize mismatch for ball_encoder.rnn.weight_hh_l0: copying a param with shape torch.Size([1024, 256]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for ball_encoder.rnn.bias_ih_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for ball_encoder.rnn.bias_hh_l0: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for decoder.fc.weight: copying a param with shape torch.Size([1, 768]) from checkpoint, the shape in current model is torch.Size([1, 384])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "from model_utils import  EncoderDecoderModel\n",
    "\n",
    "model = EncoderDecoderModel(\n",
    "    team_input_size=train_team_data[0].shape[0],\n",
    "    player_input_channels=1,  # Assuming player data is 2D and needs a channel dimension\n",
    "    ball_input_size=train_ball_data[0].shape[1],\n",
    "    hidden_size=128,\n",
    "    num_layers=1,\n",
    "    num_classes=1,\n",
    "    dropout=0.5631325927251238\n",
    ").to(device)  # Move model to device\n",
    "    \n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(artifact_dir, 'best_model.pth',), map_location=device, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\chavv\\AppData\\Local\\Temp\\ipykernel_37924\\43199998.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(os.path.join(artifact_dir, 'best_model.pth'), map_location=device))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(os.path.join(artifact_dir, 'best_model.pth'), map_location=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 0.7046, Acc: 49.64%, Val Loss: 0.7059, Val Acc: 58.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Loss: 0.6790, Acc: 49.76%, Val Loss: 0.6805, Val Acc: 58.25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Loss: 0.6613, Acc: 56.51%, Val Loss: 0.6784, Val Acc: 66.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Loss: 0.6584, Acc: 63.17%, Val Loss: 0.6720, Val Acc: 68.28%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Loss: 0.6481, Acc: 68.18%, Val Loss: 0.6692, Val Acc: 69.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Loss: 0.6472, Acc: 68.63%, Val Loss: 0.6751, Val Acc: 69.09%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Loss: 0.6458, Acc: 68.61%, Val Loss: 0.6742, Val Acc: 70.23%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Loss: 0.6405, Acc: 70.15%, Val Loss: 0.6675, Val Acc: 72.17%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:03<00:00, 19.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Loss: 0.6383, Acc: 70.37%, Val Loss: 0.6676, Val Acc: 71.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 0.6376, Acc: 70.27%, Val Loss: 0.6663, Val Acc: 69.26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.6324, Acc: 70.55%, Val Loss: 0.6630, Val Acc: 71.20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Loss: 0.6371, Acc: 69.22%, Val Loss: 0.6644, Val Acc: 69.42%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Loss: 0.6375, Acc: 69.60%, Val Loss: 0.6737, Val Acc: 71.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Loss: 0.6229, Acc: 74.60%, Val Loss: 0.6629, Val Acc: 72.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Loss: 0.6161, Acc: 75.30%, Val Loss: 0.6593, Val Acc: 72.49%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Loss: 0.6180, Acc: 75.16%, Val Loss: 0.6626, Val Acc: 73.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Loss: 0.6226, Acc: 73.30%, Val Loss: 0.6660, Val Acc: 74.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Loss: 0.6186, Acc: 76.64%, Val Loss: 0.6672, Val Acc: 74.43%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Loss: 0.6230, Acc: 74.78%, Val Loss: 0.6660, Val Acc: 73.79%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Loss: 0.6218, Acc: 74.96%, Val Loss: 0.6891, Val Acc: 72.33%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Loss: 0.6315, Acc: 74.51%, Val Loss: 0.6702, Val Acc: 74.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Loss: 0.6243, Acc: 73.69%, Val Loss: 0.6674, Val Acc: 74.76%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 18.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Loss: 0.6191, Acc: 76.40%, Val Loss: 0.6960, Val Acc: 71.84%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Loss: 0.6171, Acc: 77.06%, Val Loss: 0.6660, Val Acc: 74.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:04<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Loss: 0.6222, Acc: 77.10%, Val Loss: 0.6893, Val Acc: 72.17%\n",
      "Early stopping!\n"
     ]
    }
   ],
   "source": [
    "from model_utils import  EncoderDecoderModel\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = EncoderDecoderModel(\n",
    "    team_input_size=train_team_data[0].shape[0],\n",
    "    player_input_channels=1,  # Assuming player data is 2D and needs a channel dimension\n",
    "    ball_input_size=train_ball_data[0].shape[1],\n",
    "    hidden_size=config['hidden_size'],\n",
    "    num_layers=config['num_layers'],\n",
    "    num_classes=1,\n",
    "    dropout=config['dropout']\n",
    ").to(device)  # Move model to device\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'model_checkpoints')\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=20, factor=0.1)\n",
    "\n",
    "# Step 4: Train Model\n",
    "best_val_loss = float('inf')\n",
    "patience = 10\n",
    "trigger_times = 0\n",
    "num_epochs = 100\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0\n",
    "    total = 0\n",
    "    for team, player, ball, labels in tqdm(train_dataloader):\n",
    "        team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "        labels = labels.float()\n",
    "        outputs = model(team, player, ball)\n",
    "        loss = criterion(outputs, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        total += labels.size(0)\n",
    "        running_corrects += (predicted == labels).sum().item()\n",
    "    avg_loss = running_loss / len(train_dataloader)\n",
    "    train_acc = 100 * running_corrects / total\n",
    "\n",
    "    train_losses.append(avg_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    val_corrects = 0\n",
    "    val_total = 0\n",
    "    with torch.no_grad():\n",
    "        for team, player, ball, labels in val_dataloader:\n",
    "            team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "            labels = labels.float()\n",
    "            outputs = model(team, player, ball)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            predicted = (outputs.data > 0.5).float()\n",
    "            val_total += labels.size(0)\n",
    "            val_corrects += (predicted == labels).sum().item()\n",
    "    avg_val_loss = val_loss / len(val_dataloader)\n",
    "    val_acc = 100 * val_corrects / val_total\n",
    "\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}, Acc: {train_acc:.2f}%, Val Loss: {avg_val_loss:.4f}, Val Acc: {val_acc:.2f}%')\n",
    "\n",
    "    # Log metrics to Weights & Biases\n",
    "    wandb.log({\n",
    "        \"epoch\": epoch + 1,\n",
    "        \"train_loss\": avg_loss,\n",
    "        \"train_accuracy\": train_acc,\n",
    "        \"val_loss\": avg_val_loss,\n",
    "        \"val_accuracy\": val_acc\n",
    "    })\n",
    "\n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        trigger_times = 0\n",
    "        # Save the best model locally\n",
    "        torch.save(model.state_dict(), os.path.join(save_dir, 'best_model.pth'))\n",
    "        # Create a Weights & Biases Artifact\n",
    "        model_artifact = wandb.Artifact('best_model', type='model')\n",
    "        model_artifact.add_file(os.path.join(save_dir, 'best_model.pth'))\n",
    "        # Log the Artifact\n",
    "        wandb.log_artifact(model_artifact)\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print('Early stopping!')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.53 %\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "all_labels = []\n",
    "all_predictions = []\n",
    "all_probs = []\n",
    "\n",
    "# Define window sizes\n",
    "window_sizes = [20, 25, 30, 35, 40, 45]\n",
    "stage_metrics = {}\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, roc_curve, auc\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for team, player, ball, labels in test_dataloader:\n",
    "        team, player, ball, labels = team.to(device), player.to(device), ball.to(device), labels.to(device)  # Move data to device\n",
    "        team = team.float()\n",
    "        player = player.float()\n",
    "        ball = ball.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        outputs = model(team, player, ball)\n",
    "        probs = outputs.squeeze().cpu().numpy()\n",
    "        if probs.ndim == 0:\n",
    "            probs = probs.reshape(1)  # Convert scalar to 1D array\n",
    "        predicted = (outputs.data > 0.5).float()\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "        all_predictions.extend(predicted.cpu().numpy())\n",
    "        all_probs.extend(probs)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    print('Test Accuracy: {:.2f} %'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
