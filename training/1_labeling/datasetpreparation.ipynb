{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F  # Import F module\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data using polars\n",
    "directory = r'D:\\github\\Cricket-prediction\\data\\4_filteredData'\n",
    "balltoball = pl.read_csv(os.path.join(directory, 'balltoball.csv'))\n",
    "teamStats = pl.read_csv(os.path.join(directory, 'team12Stats.csv'))\n",
    "playersStats = pl.read_csv(os.path.join(directory, 'playersStats.csv'))\n",
    "\n",
    "# Preprocess the data\n",
    "def partition_data(df, group_keys):\n",
    "    partitions = df.partition_by(group_keys)\n",
    "    partition_list = [partition.drop(group_keys).to_numpy() for partition in partitions]\n",
    "    return partition_list\n",
    "\n",
    "team_stats_partitions = partition_data(teamStats, ['match_id', 'flip'])\n",
    "player_stats_partitions = partition_data(playersStats, ['match_id', 'flip'])\n",
    "ball_stats_partitions = partition_data(balltoball, ['match_id', 'flip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_312, 25)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>match_id</th><th>flip</th><th>gender</th><th>Mat</th><th>Won</th><th>Lost</th><th>Tied</th><th>NR</th><th>W/L</th><th>Inns</th><th>HS</th><th>LS</th><th>AveRPW</th><th>AveRPO</th><th>Mat_team2</th><th>Won_team2</th><th>Lost_team2</th><th>Tied_team2</th><th>NR_team2</th><th>W/L_team2</th><th>Inns_team2</th><th>HS_team2</th><th>LS_team2</th><th>AveRPW_team2</th><th>AveRPO_team2</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>211028</td><td>0</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.0</td><td>1</td><td>179</td><td>0.0</td><td>22.37</td><td>8.95</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0.0</td><td>1</td><td>79</td><td>79.0</td><td>7.9</td><td>5.44</td></tr><tr><td>211028</td><td>1</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0.0</td><td>1</td><td>79</td><td>79.0</td><td>7.9</td><td>5.44</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.0</td><td>1</td><td>179</td><td>0.0</td><td>22.37</td><td>8.95</td></tr><tr><td>211048</td><td>0</td><td>1</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0.0</td><td>1</td><td>170</td><td>170.0</td><td>17.0</td><td>8.5</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.0</td><td>1</td><td>214</td><td>0.0</td><td>42.8</td><td>10.7</td></tr><tr><td>211048</td><td>1</td><td>1</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.0</td><td>1</td><td>214</td><td>0.0</td><td>42.8</td><td>10.7</td><td>1</td><td>0</td><td>1</td><td>0</td><td>0</td><td>0.0</td><td>1</td><td>170</td><td>170.0</td><td>17.0</td><td>8.5</td></tr><tr><td>225263</td><td>0</td><td>1</td><td>2</td><td>0</td><td>2</td><td>0</td><td>0</td><td>0.0</td><td>2</td><td>161</td><td>0.0</td><td>25.41</td><td>7.62</td><td>1</td><td>1</td><td>0</td><td>0</td><td>0</td><td>1.0</td><td>1</td><td>148</td><td>0.0</td><td>29.6</td><td>8.29</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>1450753</td><td>1</td><td>1</td><td>5</td><td>5</td><td>0</td><td>0</td><td>0</td><td>5.0</td><td>5</td><td>183</td><td>119.0</td><td>21.28</td><td>7.81</td><td>5</td><td>0</td><td>5</td><td>0</td><td>0</td><td>0.0</td><td>5</td><td>57</td><td>18.0</td><td>3.56</td><td>2.67</td></tr><tr><td>1450759</td><td>0</td><td>1</td><td>5</td><td>0</td><td>5</td><td>0</td><td>0</td><td>0.0</td><td>5</td><td>57</td><td>18.0</td><td>3.56</td><td>2.67</td><td>10</td><td>6</td><td>4</td><td>0</td><td>0</td><td>1.5</td><td>10</td><td>176</td><td>100.0</td><td>26.9</td><td>7.11</td></tr><tr><td>1450759</td><td>1</td><td>1</td><td>10</td><td>6</td><td>4</td><td>0</td><td>0</td><td>1.5</td><td>10</td><td>176</td><td>100.0</td><td>26.9</td><td>7.11</td><td>5</td><td>0</td><td>5</td><td>0</td><td>0</td><td>0.0</td><td>5</td><td>57</td><td>18.0</td><td>3.56</td><td>2.67</td></tr><tr><td>1450765</td><td>0</td><td>1</td><td>5</td><td>5</td><td>0</td><td>0</td><td>0</td><td>5.0</td><td>5</td><td>183</td><td>119.0</td><td>21.28</td><td>7.81</td><td>10</td><td>6</td><td>4</td><td>0</td><td>0</td><td>1.5</td><td>10</td><td>176</td><td>100.0</td><td>26.9</td><td>7.11</td></tr><tr><td>1450765</td><td>1</td><td>1</td><td>10</td><td>6</td><td>4</td><td>0</td><td>0</td><td>1.5</td><td>10</td><td>176</td><td>100.0</td><td>26.9</td><td>7.11</td><td>5</td><td>5</td><td>0</td><td>0</td><td>0</td><td>5.0</td><td>5</td><td>183</td><td>119.0</td><td>21.28</td><td>7.81</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_312, 25)\n",
       "┌──────────┬──────┬────────┬─────┬───┬──────────┬──────────┬──────────────┬──────────────┐\n",
       "│ match_id ┆ flip ┆ gender ┆ Mat ┆ … ┆ HS_team2 ┆ LS_team2 ┆ AveRPW_team2 ┆ AveRPO_team2 │\n",
       "│ ---      ┆ ---  ┆ ---    ┆ --- ┆   ┆ ---      ┆ ---      ┆ ---          ┆ ---          │\n",
       "│ i64      ┆ i64  ┆ i64    ┆ i64 ┆   ┆ i64      ┆ f64      ┆ f64          ┆ f64          │\n",
       "╞══════════╪══════╪════════╪═════╪═══╪══════════╪══════════╪══════════════╪══════════════╡\n",
       "│ 211028   ┆ 0    ┆ 1      ┆ 1   ┆ … ┆ 79       ┆ 79.0     ┆ 7.9          ┆ 5.44         │\n",
       "│ 211028   ┆ 1    ┆ 1      ┆ 1   ┆ … ┆ 179      ┆ 0.0      ┆ 22.37        ┆ 8.95         │\n",
       "│ 211048   ┆ 0    ┆ 1      ┆ 1   ┆ … ┆ 214      ┆ 0.0      ┆ 42.8         ┆ 10.7         │\n",
       "│ 211048   ┆ 1    ┆ 1      ┆ 1   ┆ … ┆ 170      ┆ 170.0    ┆ 17.0         ┆ 8.5          │\n",
       "│ 225263   ┆ 0    ┆ 1      ┆ 2   ┆ … ┆ 148      ┆ 0.0      ┆ 29.6         ┆ 8.29         │\n",
       "│ …        ┆ …    ┆ …      ┆ …   ┆ … ┆ …        ┆ …        ┆ …            ┆ …            │\n",
       "│ 1450753  ┆ 1    ┆ 1      ┆ 5   ┆ … ┆ 57       ┆ 18.0     ┆ 3.56         ┆ 2.67         │\n",
       "│ 1450759  ┆ 0    ┆ 1      ┆ 5   ┆ … ┆ 176      ┆ 100.0    ┆ 26.9         ┆ 7.11         │\n",
       "│ 1450759  ┆ 1    ┆ 1      ┆ 10  ┆ … ┆ 57       ┆ 18.0     ┆ 3.56         ┆ 2.67         │\n",
       "│ 1450765  ┆ 0    ┆ 1      ┆ 5   ┆ … ┆ 176      ┆ 100.0    ┆ 26.9         ┆ 7.11         │\n",
       "│ 1450765  ┆ 1    ┆ 1      ┆ 10  ┆ … ┆ 183      ┆ 119.0    ┆ 21.28        ┆ 7.81         │\n",
       "└──────────┴──────┴────────┴─────┴───┴──────────┴──────────┴──────────────┴──────────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "teamStats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data by creating new samples with different combinations of overs\n",
    "def augment_data(team_stats_list, player_stats_list, ball_stats_list, over_segments=np.arange(6, 41)):  # Min 6 overs, max 40 overs\n",
    "    augmented_team_stats = []\n",
    "    augmented_player_stats = []\n",
    "    augmented_ball_stats = []\n",
    "    \n",
    "    for team_stats, player_stats, ball_stats in zip(team_stats_list, player_stats_list, ball_stats_list):\n",
    "        total_overs = ball_stats.shape[0] // 6  # Assuming 6 balls per over\n",
    "        for segment in over_segments:\n",
    "            if total_overs >= segment:\n",
    "                end_idx = segment * 6\n",
    "                augmented_team_stats.append(team_stats)\n",
    "                augmented_player_stats.append(player_stats)\n",
    "                augmented_ball_stats.append(ball_stats[:end_idx])\n",
    "    \n",
    "    return augmented_team_stats, augmented_player_stats, augmented_ball_stats\n",
    "\n",
    "augmented_team_stats, augmented_player_stats, augmented_ball_stats = augment_data(\n",
    "    team_stats_partitions, player_stats_partitions, ball_stats_partitions)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_team_stats, val_team_stats, train_player_stats, val_player_stats, train_ball_stats, val_ball_stats = train_test_split(\n",
    "    augmented_team_stats, augmented_player_stats, augmented_ball_stats, test_size=0.2, random_state=42)\n",
    "\n",
    "val_team_stats, test_team_stats, val_player_stats, test_player_stats, val_ball_stats, test_ball_stats = train_test_split(\n",
    "    val_team_stats, val_player_stats, val_ball_stats, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a custom Dataset\n",
    "class CricketDataset(Dataset):\n",
    "    def __init__(self, team_stats_list, player_stats_list, ball_stats_list):\n",
    "        self.team_stats_list = team_stats_list\n",
    "        self.player_stats_list = player_stats_list\n",
    "        self.ball_stats_list = ball_stats_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.team_stats_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        team_input = torch.tensor(self.team_stats_list[idx], dtype=torch.float32)\n",
    "        team_input = team_input.squeeze()  # Remove extra dimensions\n",
    "        player_input = torch.tensor(self.player_stats_list[idx], dtype=torch.float32)\n",
    "        ball_stats = torch.tensor(self.ball_stats_list[idx], dtype=torch.float32)\n",
    "        # Assuming the last column is the label\n",
    "        ball_input = ball_stats[:, :-1]\n",
    "        label = ball_stats[0, -1]\n",
    "        return team_input, player_input, ball_input, label\n",
    "\n",
    "# Define a collate function to handle variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    team_inputs = []\n",
    "    player_inputs = []\n",
    "    ball_inputs = []\n",
    "    labels = []\n",
    "    ball_lengths = []\n",
    "\n",
    "    for team_input, player_input, ball_input, label in batch:\n",
    "        team_inputs.append(team_input)\n",
    "        player_inputs.append(player_input)\n",
    "        ball_inputs.append(ball_input)\n",
    "        labels.append(label)\n",
    "        ball_lengths.append(ball_input.shape[0])\n",
    "\n",
    "    # Pad ball_inputs to the maximum sequence length in the batch\n",
    "    max_seq_len = max(ball_lengths)\n",
    "    padded_ball_inputs = torch.zeros(len(ball_inputs), max_seq_len, ball_inputs[0].shape[1])\n",
    "    for i, ball_input in enumerate(ball_inputs):\n",
    "        seq_len = ball_input.shape[0]\n",
    "        padded_ball_inputs[i, :seq_len, :] = ball_input\n",
    "\n",
    "    team_inputs = torch.stack(team_inputs)\n",
    "    player_inputs = torch.stack(player_inputs)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return team_inputs, player_inputs, padded_ball_inputs, labels, ball_lengths\n",
    "\n",
    "# Create the training and validation datasets and dataloaders\n",
    "train_dataset = CricketDataset(train_team_stats, train_player_stats, train_ball_stats)\n",
    "val_dataset = CricketDataset(val_team_stats, val_player_stats, val_ball_stats)\n",
    "test_dataset = CricketDataset(test_team_stats, test_player_stats, test_ball_stats)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 234, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 240, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 216, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 228, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 234, 4]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for team_inputs, player_inputs, ball_inputs, labels, ball_lengths in train_dataloader:\n",
    "    print(team_inputs.shape, player_inputs.shape, ball_inputs.shape, labels.shape)\n",
    "    i += 1\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataloaders\n",
    "import pickle\n",
    "\n",
    "# Save dataloaders\n",
    "with open(os.path.join(directory, '../pytorchData\\\\train_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_dataloader, f)\n",
    "with open(os.path.join(directory, '../pytorchData\\\\val_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_dataloader, f)\n",
    "with open(os.path.join(directory, '../pytorchData\\\\test_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
