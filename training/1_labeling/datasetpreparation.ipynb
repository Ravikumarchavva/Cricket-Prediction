{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F  # Import F module\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data using polars\n",
    "directory = r'D:\\github\\Cricket-prediction\\data\\filteredData'\n",
    "balltoball = pl.read_csv(os.path.join(directory, 'balltoball.csv'))\n",
    "teamStats = pl.read_csv(os.path.join(directory, 'team12Stats.csv'))\n",
    "playersStats = pl.read_csv(os.path.join(directory, 'playersStats.csv'))\n",
    "\n",
    "# Preprocess the data\n",
    "def partition_data(df, group_keys):\n",
    "    partitions = df.partition_by(group_keys)\n",
    "    partition_list = [partition.drop(group_keys).to_numpy() for partition in partitions]\n",
    "    return partition_list\n",
    "\n",
    "team_stats_partitions = partition_data(teamStats, ['match_id', 'flip'])\n",
    "player_stats_partitions = partition_data(playersStats, ['match_id', 'flip'])\n",
    "ball_stats_partitions = partition_data(balltoball, ['match_id', 'flip'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment the data by creating new samples with different combinations of overs\n",
    "def augment_data(team_stats_list, player_stats_list, ball_stats_list, over_segments=np.arange(6, 41)):  # Min 6 overs, max 40 overs\n",
    "    augmented_team_stats = []\n",
    "    augmented_player_stats = []\n",
    "    augmented_ball_stats = []\n",
    "    \n",
    "    for team_stats, player_stats, ball_stats in zip(team_stats_list, player_stats_list, ball_stats_list):\n",
    "        total_overs = ball_stats.shape[0] // 6  # Assuming 6 balls per over\n",
    "        for segment in over_segments:\n",
    "            if total_overs >= segment:\n",
    "                end_idx = segment * 6\n",
    "                augmented_team_stats.append(team_stats)\n",
    "                augmented_player_stats.append(player_stats)\n",
    "                augmented_ball_stats.append(ball_stats[:end_idx])\n",
    "    \n",
    "    return augmented_team_stats, augmented_player_stats, augmented_ball_stats\n",
    "\n",
    "augmented_team_stats, augmented_player_stats, augmented_ball_stats = augment_data(\n",
    "    team_stats_partitions, player_stats_partitions, ball_stats_partitions)\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "train_team_stats, val_team_stats, train_player_stats, val_player_stats, train_ball_stats, val_ball_stats = train_test_split(\n",
    "    augmented_team_stats, augmented_player_stats, augmented_ball_stats, test_size=0.2, random_state=42)\n",
    "\n",
    "val_team_stats, test_team_stats, val_player_stats, test_player_stats, val_ball_stats, test_ball_stats = train_test_split(\n",
    "    val_team_stats, val_player_stats, val_ball_stats, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a custom Dataset\n",
    "class CricketDataset(Dataset):\n",
    "    def __init__(self, team_stats_list, player_stats_list, ball_stats_list):\n",
    "        self.team_stats_list = team_stats_list\n",
    "        self.player_stats_list = player_stats_list\n",
    "        self.ball_stats_list = ball_stats_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.team_stats_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        team_input = torch.tensor(self.team_stats_list[idx], dtype=torch.float32)\n",
    "        team_input = team_input.squeeze()  # Remove extra dimensions\n",
    "        player_input = torch.tensor(self.player_stats_list[idx], dtype=torch.float32)\n",
    "        ball_stats = torch.tensor(self.ball_stats_list[idx], dtype=torch.float32)\n",
    "        # Assuming the last column is the label\n",
    "        ball_input = ball_stats[:, :-1]\n",
    "        label = ball_stats[0, -1]\n",
    "        return team_input, player_input, ball_input, label\n",
    "\n",
    "# Define a collate function to handle variable-length sequences\n",
    "def collate_fn(batch):\n",
    "    team_inputs = []\n",
    "    player_inputs = []\n",
    "    ball_inputs = []\n",
    "    labels = []\n",
    "    ball_lengths = []\n",
    "\n",
    "    for team_input, player_input, ball_input, label in batch:\n",
    "        team_inputs.append(team_input)\n",
    "        player_inputs.append(player_input)\n",
    "        ball_inputs.append(ball_input)\n",
    "        labels.append(label)\n",
    "        ball_lengths.append(ball_input.shape[0])\n",
    "\n",
    "    # Pad ball_inputs to the maximum sequence length in the batch\n",
    "    max_seq_len = max(ball_lengths)\n",
    "    padded_ball_inputs = torch.zeros(len(ball_inputs), max_seq_len, ball_inputs[0].shape[1])\n",
    "    for i, ball_input in enumerate(ball_inputs):\n",
    "        seq_len = ball_input.shape[0]\n",
    "        padded_ball_inputs[i, :seq_len, :] = ball_input\n",
    "\n",
    "    team_inputs = torch.stack(team_inputs)\n",
    "    player_inputs = torch.stack(player_inputs)\n",
    "    labels = torch.tensor(labels, dtype=torch.float32)\n",
    "    return team_inputs, player_inputs, padded_ball_inputs, labels, ball_lengths\n",
    "\n",
    "# Create the training and validation datasets and dataloaders\n",
    "train_dataset = CricketDataset(train_team_stats, train_player_stats, train_ball_stats)\n",
    "val_dataset = CricketDataset(val_team_stats, val_player_stats, val_ball_stats)\n",
    "test_dataset = CricketDataset(test_team_stats, test_player_stats, test_ball_stats)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 234, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 240, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 216, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 228, 4]) torch.Size([16])\n",
      "torch.Size([16, 23]) torch.Size([16, 22, 22]) torch.Size([16, 234, 4]) torch.Size([16])\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for team_inputs, player_inputs, ball_inputs, labels, ball_lengths in train_dataloader:\n",
    "    print(team_inputs.shape, player_inputs.shape, ball_inputs.shape, labels.shape)\n",
    "    i += 1\n",
    "    if i >= 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataloaders\n",
    "import pickle\n",
    "\n",
    "# Save dataloaders\n",
    "with open(os.path.join(directory, '../pytorchData\\\\train_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(train_dataloader, f)\n",
    "with open(os.path.join(directory, '../pytorchData\\\\val_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(val_dataloader, f)\n",
    "with open(os.path.join(directory, '../pytorchData\\\\test_dataloader.pkl'), 'wb') as f:\n",
    "    pickle.dump(test_dataloader, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "huggingface-torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
