{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---+----+---+---+---+-----+-----+-----------+-----+-------+\n",
      "|              Player|Mat|Inns|Dis| Ct| St|Ct Wk|Ct Fi|         MD|  D/I| Season|\n",
      "+--------------------+---+----+---+---+---+-----+-----+-----------+-----+-------+\n",
      "|Zulqarnain Haider...|  2|   2|  1|  0|  1|    0|    0|1 (0ct 1st)|  0.5|2010/11|\n",
      "|Zulqarnain Haider...|  1|   1|  0|  0|  0|    0|    0|          0|  0.0|2006/07|\n",
      "|Zulqarnain Haider...|  6|   6|  0|  0|  0|    0|    0|          0|  0.0|   2022|\n",
      "|Zulqarnain Haider...|  1|   1|  0|  0|  0|    0|    0|          0|0.000|2019/20|\n",
      "|Zulqarnain Haider...|  4|   4|  1|  1|  0|    0|    1|1 (1ct 0st)| 0.25|   2019|\n",
      "+--------------------+---+----+---+---+---+-----+-----+-----------+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "\n",
    "\n",
    "# Then proceed to import and use Spark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"CricketPrediction\").getOrCreate()\n",
    "\n",
    "\n",
    "# Specify the directory where your CSV files are located\n",
    "directory = r'D:\\github\\Cricket-Prediction\\data\\1_rawData'\n",
    "fielding_data = spark.read.csv(os.path.join(directory, 't20_fielding_stats.csv'), header=True, inferSchema=True)\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "|          Player|Mat|Inns|Dis| Ct| St|  D/I| Season|\n",
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "|A Ahmadhel (BUL)|  3|   3|  0|  0|  0|  0.0|2019/20|\n",
      "|A Ahmadhel (BUL)|  1|   1|  0|  0|  0|0.000|   2020|\n",
      "|A Ahmadhel (BUL)|  2|   2|  0|  0|  0|0.000|2020/21|\n",
      "|A Ahmadhel (BUL)|  3|   3|  0|  0|  0|  0.0|   2021|\n",
      "|A Ahmadhel (BUL)|  2|   1|  0|  0|  0|  0.0|   2023|\n",
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.select(['Player',\"Mat\",\"Inns\",\"Dis\",\"Ct\",\"St\",\"D/I\",\"Season\"]).sort([\"Player\",\"Season\"])\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+----+---+---+---+---+-------+\n",
      "|          Player|Mat|Inns|Dis| Ct| St|D/I| Season|\n",
      "+----------------+---+----+---+---+---+---+-------+\n",
      "|A Ahmadhel (BUL)|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|\n",
      "|A Ahmadhel (BUL)|  1| 1.0|0.0|0.0|0.0|0.0|   2020|\n",
      "|A Ahmadhel (BUL)|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|\n",
      "|A Ahmadhel (BUL)|  3| 3.0|0.0|0.0|0.0|0.0|   2021|\n",
      "|A Ahmadhel (BUL)|  2| 1.0|0.0|0.0|0.0|0.0|   2023|\n",
      "+----------------+---+----+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "fielding_data = fielding_data.withColumn('Inns', when(col('Inns') == '-', '0').otherwise(col('Inns')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('Dis', when(col('Dis') == '-', '0').otherwise(col('Dis')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('Ct', when(col('Ct') == '-', '0').otherwise(col('Ct')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('St', when(col('St') == '-', '0').otherwise(col('St')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('D/I', when(col('D/I') == '-', col('Dis')/col('Inns')).otherwise(col('D/I')).cast('float')).fillna(0)\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "|    Player|Mat|Inns|Dis| Ct| St|D/I| Season|Country|\n",
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|    BUL|\n",
      "|A Ahmadhel|  1| 1.0|0.0|0.0|0.0|0.0|   2020|    BUL|\n",
      "|A Ahmadhel|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|    BUL|\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|   2021|    BUL|\n",
      "|A Ahmadhel|  2| 1.0|0.0|0.0|0.0|0.0|   2023|    BUL|\n",
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "\n",
    "# Extract the country name between '(' and ')'\n",
    "fielding_data = fielding_data.withColumn(\"Country\", regexp_extract(col(\"Player\"), r\"\\((.*?)\\)\", 1))\n",
    "\n",
    "# Extract the player's name before the first '('\n",
    "fielding_data = fielding_data.withColumn(\"Player\", regexp_extract(col(\"Player\"), r\"^(.*?)\\s\\(\", 1))\n",
    "\n",
    "# Show the result\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+----+---+---+---+-----+-------+-------+--------------+-------------+-------------+--------------+\n",
      "|     Player|Mat|Inns|Dis| Ct| St|  D/I| Season|Country|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+-----------+---+----+---+---+---+-----+-------+-------+--------------+-------------+-------------+--------------+\n",
      "| A Ahmadhel|  3| 3.0|0.0|0.0|0.0|  0.0|2019/20|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "| A Ahmadhel|  1| 1.0|0.0|0.0|0.0|  0.0|   2020|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "| A Ahmadhel|  2| 2.0|0.0|0.0|0.0|  0.0|2020/21|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "| A Ahmadhel|  3| 3.0|0.0|0.0|0.0|  0.0|   2021|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "| A Ahmadhel|  2| 1.0|0.0|0.0|0.0|  0.0|   2023|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "| A Ahmadhel|  1| 1.0|1.0|1.0|0.0|  1.0|   2024|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Alexander|  1| 1.0|0.0|0.0|0.0|  0.0|2024/25|    INA|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Amado|  3| 3.0|2.0|2.0|0.0|0.666|   2022|    ISR|           0.0|          0.0|          0.0|           0.0|\n",
      "|  A Andrews|  3| 3.0|4.0|4.0|0.0|1.333|2021/22|    SUI|           0.0|          0.0|          0.0|           0.0|\n",
      "|  A Andrews|  4| 4.0|3.0|3.0|0.0| 0.75|   2022|    SUI|           4.0|          4.0|          0.0|          1.33|\n",
      "+-----------+---+----+---+---+---+-----+-------+-------+--------------+-------------+-------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when, row_number, round\n",
    "\n",
    "# Define the window specification for cumulative calculations\n",
    "window_spec = Window.partitionBy(\"Player\", \"Country\").orderBy(\"Season\").rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "# Window for row number to identify the first row per player and country\n",
    "row_num_window = Window.partitionBy(\"Player\", \"Country\").orderBy(\"Season\")\n",
    "\n",
    "# Perform cumulative calculations with conditions\n",
    "fielding_data = fielding_data.withColumn(\"row_num\", row_number().over(row_num_window)) \\\n",
    "    .withColumn(\"Cumulative Dis\", \n",
    "                when(col(\"row_num\") == 1, 0)  # Set 0 for the first row (before any match)\n",
    "                .otherwise(spark_sum(\"Dis\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative Ct\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(spark_sum(\"Ct\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative St\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(spark_sum(\"St\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative D/I\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(\n",
    "                    round(\n",
    "                        when(spark_sum(\"Inns\").over(window_spec) != 0, \n",
    "                             spark_sum(\"Dis\").over(window_spec) / spark_sum(\"Inns\").over(window_spec))\n",
    "                        .otherwise(0), 2)\n",
    "                )\n",
    "    ) \\\n",
    "    .drop(\"row_num\")  # Drop the temporary row number column\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "fielding_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+----+---+---+---+---+------+-------+--------------+-------------+-------------+--------------+\n",
      "|Player|Mat|Inns|Dis| Ct| St|D/I|Season|Country|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+------+---+----+---+---+---+---+------+-------+--------------+-------------+-------------+--------------+\n",
      "|     0|  0|   0|  0|  0|  0|  0|     0|      0|             0|            0|            0|             0|\n",
      "+------+---+----+---+---+---+---+------+-------+--------------+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate null count\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "\n",
    "fielding_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fielding_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 11, 5, 103)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes = {\n",
    "    'LES': 'Lesotho',\n",
    "    'BUL': 'Bulgaria',\n",
    "    'VAN': 'Vanuatu',\n",
    "    'ROM': 'Romania',\n",
    "    'Aut': 'Austria',\n",
    "    'COK': 'Cook Islands',\n",
    "    'Fran': 'France',\n",
    "    'SRB': 'Serbia',\n",
    "    'PAK': 'Pakistan',\n",
    "    'HUN': 'Hungary',\n",
    "    'CYP': 'Cyprus',\n",
    "    'Fiji': 'Fiji',\n",
    "    'FIN': 'Finland',\n",
    "    'EST': 'Estonia',\n",
    "    'CHN': 'China',\n",
    "    'GRC': 'Greece',\n",
    "    'CAM': 'Cambodia',\n",
    "    'GUE': 'Guernsey',\n",
    "    'SEY': 'Seychelles',\n",
    "    'JPN': 'Japan',\n",
    "    'TAN': 'Tanzania',\n",
    "    'JER': 'Jersey',\n",
    "    'QAT': 'Qatar',\n",
    "    'ENG': 'England',\n",
    "    'UGA': 'Uganda',\n",
    "    'BER': 'Bermuda',\n",
    "    'CZK-R': 'Czech Republic',\n",
    "    'CAY': 'Cayman Islands',\n",
    "    'IRE': 'Ireland',\n",
    "    'Mali': 'Mali',\n",
    "    'BRA': 'Brazil',\n",
    "    'SUI': 'Switzerland',\n",
    "    'Peru': 'Peru',\n",
    "    'Mex': 'Mexico',\n",
    "    'MOZ': 'Mozambique',\n",
    "    'Samoa': 'Samoa',\n",
    "    'HKG': 'Hong Kong',\n",
    "    'BAN': 'Bangladesh',\n",
    "    'SL': 'Sri Lanka',\n",
    "    'PNG': 'Papua New Guinea',\n",
    "    'ZIM': 'Zimbabwe',\n",
    "    'GHA': 'Ghana',\n",
    "    'SWZ': 'Eswatini',  # Swaziland's official name now is Eswatini\n",
    "    'MYAN': 'Myanmar',\n",
    "    'IND': 'India',\n",
    "    'USA': 'United States of America',\n",
    "    'NEP': 'Nepal',\n",
    "    'AFG': 'Afghanistan',\n",
    "    'PAN': 'Panama',\n",
    "    'NGA': 'Nigeria',\n",
    "    'SLE': 'Sierra Leone',\n",
    "    'ESP': 'Spain',\n",
    "    'Bhm': 'Bahamas',\n",
    "    'TKY': 'Turkey',\n",
    "    'MWI': 'Malawi',\n",
    "    'WI': 'West Indies',\n",
    "    'IOM': 'Isle of Man',\n",
    "    'THA': 'Thailand',\n",
    "    'SWA': 'Eswatini',  # another code for Eswatini\n",
    "    'SKOR': 'South Korea',\n",
    "    'GMB': 'Gambia',\n",
    "    'ISR': 'Israel',\n",
    "    'KUW': 'Kuwait',\n",
    "    'Belg': 'Belgium',\n",
    "    'GER': 'Germany',\n",
    "    'ITA': 'Italy',\n",
    "    'CAN': 'Canada',\n",
    "    'MDV': 'Maldives',\n",
    "    'Blz': 'Belize',\n",
    "    'DEN': 'Denmark',\n",
    "    'INA': 'Indonesia',\n",
    "    'KENYA': 'Kenya',\n",
    "    'LUX': 'Luxembourg',\n",
    "    'STHEL': 'Saint Helena',\n",
    "    'BHR': 'Bahrain',\n",
    "    'KSA': 'Saudi Arabia',\n",
    "    'MLT': 'Malta',\n",
    "    'Arg': 'Argentina',\n",
    "    'MNG': 'Mongolia',\n",
    "    'AUS': 'Australia',\n",
    "    'GIBR': 'Gibraltar',\n",
    "    'SGP': 'Singapore',\n",
    "    'Chile': 'Chile',\n",
    "    'UAE': 'United Arab Emirates',\n",
    "    'NZ': 'New Zealand',\n",
    "    'SCOT': 'Scotland',\n",
    "    'BHU': 'Bhutan',\n",
    "    'MAS': 'Malaysia',\n",
    "    'BOT': 'Botswana',\n",
    "    'CRC': 'Costa Rica',\n",
    "    'PHI': 'Philippines',\n",
    "    'NAM': 'Namibia',\n",
    "    'RWN': 'Rwanda',\n",
    "    'OMA': 'Oman',\n",
    "    'NOR': 'Norway',\n",
    "    'CRT': 'Croatia',\n",
    "    'SWE': 'Sweden',\n",
    "    'Iran': 'Iran',\n",
    "    'PORT': 'Portugal',\n",
    "    'NED': 'Netherlands',\n",
    "    'SA': 'South Africa',\n",
    "    'SVN': 'Slovenia',\n",
    "    'GUE': 'Guernsey',\n",
    "    'MDV': 'Maldives',\n",
    "    'BHM': 'Bahamas',\n",
    "    'SWE': 'Sweden',\n",
    "    'MLT': 'Malta',\n",
    "    'ITA': 'Italy',\n",
    "}\n",
    "\n",
    "# ICC and World teams\n",
    "icc_world = {\n",
    "    'ICC/PAK': 'Pakistan',\n",
    "    'ICC/SL': 'Sri Lanka',\n",
    "    'ICC/IND': 'India',\n",
    "    'ICC/NEP': 'Nepal',\n",
    "    'BAN/ICC': 'Bangladesh',\n",
    "    'AFG/ICC': 'Afghanistan',\n",
    "    'SL/World': 'Sri Lanka',\n",
    "    'SA/World': 'South Africa',\n",
    "    'AUS/World': 'Australia',\n",
    "    'BAN/World': 'Bangladesh',\n",
    "    'WI/World': 'West Indies',\n",
    "}\n",
    "\n",
    "# Outlier/Miscellaneous Countries\n",
    "outlier_countries = {\n",
    "    '1': 'Miscellaneous Country 1',\n",
    "    '2': 'Miscellaneous Country 2',\n",
    "    '3': 'Miscellaneous Country 3',\n",
    "    'ICC': 'International Cricket Council',\n",
    "    'World': 'World XI',\n",
    "}\n",
    "\n",
    "# Filtered country codes excluding ICC, World teams, and miscellaneous\n",
    "filtered_countries = {\n",
    "    code: country\n",
    "    for code, country in country_codes.items()\n",
    "    if code not in icc_world and code not in outlier_countries\n",
    "}\n",
    "len(country_codes), len(icc_world), len(outlier_countries), len(filtered_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+---+---+---+---+-------+-------+--------------+-------------+-------------+--------------+\n",
      "|    Player|Mat|Inns|Dis| Ct| St|D/I| Season|Country|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+---+----+---+---+---+---+-------+-------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  1| 1.0|0.0|0.0|0.0|0.0|   2020|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|   2021|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  2| 1.0|0.0|0.0|0.0|0.0|   2023|    BUL|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+---+----+---+---+---+---+-------+-------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.filter(col('Country').isin(list(filtered_countries.keys())))\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+---+---+---+---+-------+--------+--------------+-------------+-------------+--------------+\n",
      "|    Player|Mat|Inns|Dis| Ct| St|D/I| Season| Country|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+---+----+---+---+---+---+-------+--------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|Bulgaria|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  1| 1.0|0.0|0.0|0.0|0.0|   2020|Bulgaria|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|Bulgaria|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|   2021|Bulgaria|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|  2| 1.0|0.0|0.0|0.0|0.0|   2023|Bulgaria|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+---+----+---+---+---+---+-------+--------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.replace(filtered_countries,subset=['Country'])\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4129, 4074, 14035)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fielding_data[['Player','Country']].distinct().count(), fielding_data[['Player']].distinct().count(), fielding_data.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
