{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-15T10:48:16.700+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m12} INFO\u001b[0m - Creating Spark session.\u001b[0m\n",
      "[\u001b[34m2024-11-15T10:48:16.731+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m30} INFO\u001b[0m - Spark session created successfully.\u001b[0m\n",
      "[\u001b[34m2024-11-15T10:48:16.733+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m39} INFO\u001b[0m - Loading data from fielding_data.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 39:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-15T10:48:31.691+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m39} INFO\u001b[0m - Loading data from bowling_data.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-15T10:48:32.413+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m39} INFO\u001b[0m - Loading data from batting_data.csv.\u001b[0m\n",
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|    Player| Country| Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|Bulgaria|2019/20|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2020|             3|            3.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|2020/21|             4|            4.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2021|             6|            6.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2023|             9|            9.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..','..'))\n",
    "import config, utils\n",
    "\n",
    "# Create a Spark session\n",
    "spark = utils.create_spark_session(\"playerStats\")\n",
    "\n",
    "fielding_data = utils.load_data(spark,config.PROCESSED_DATA_DIR, 'fielding_data.csv')\n",
    "bowling_data = utils.load_data(spark,config.PROCESSED_DATA_DIR, 'bowling_data.csv')\n",
    "batting_data = utils.load_data(spark,config.PROCESSED_DATA_DIR, 'batting_data.csv')\n",
    "\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14140 14140 14140\n"
     ]
    }
   ],
   "source": [
    "print(fielding_data.count(), bowling_data.count(), batting_data.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-15T10:48:34.139+0530\u001b[0m] {\u001b[34mutils.py:\u001b[0m39} INFO\u001b[0m - Loading data from match_players.csv.\u001b[0m\n",
      "+-------+-----------+---------+-------+--------+\n",
      "|Country|     player|player_id| Season|match_id|\n",
      "+-------+-----------+---------+-------+--------+\n",
      "|England|   DN Wyatt| a139c379|2019/20| 1173063|\n",
      "|England|TT Beaumont| b2664905|2019/20| 1173063|\n",
      "|England|  NR Sciver| f3a18a0c|2019/20| 1173063|\n",
      "|England|  HC Knight| 4ba0289e|2019/20| 1173063|\n",
      "|England|  FC Wilson| a28132bd|2019/20| 1173063|\n",
      "+-------+-----------+---------+-------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import config\n",
    "from utils import load_data\n",
    "players_data = load_data(spark, config.PROCESSED_DATA_DIR, 'match_players.csv').withColumnRenamed(\"country\", \"Country\").withColumnRenamed(\"season\", \"Season\")\n",
    "players_data.show(5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------+---------------+------------------+---------------+---------------+---------------+\n",
      "|    Player| Country| Season|Cumulative Mat|Cumulative Inns|  Cumulative Overs|Cumulative Runs|Cumulative Wkts|Cumulative Econ|\n",
      "+----------+--------+-------+--------------+---------------+------------------+---------------+---------------+---------------+\n",
      "|A Ahmadhel|Bulgaria|2019/20|             0|            0.0|               0.0|            0.0|            0.0|            0.0|\n",
      "|A Ahmadhel|Bulgaria|   2020|             3|            3.0|              10.0|           75.0|            3.0|            7.5|\n",
      "|A Ahmadhel|Bulgaria|2020/21|             4|            4.0|              12.0|           97.0|            4.0|           8.38|\n",
      "|A Ahmadhel|Bulgaria|   2021|             6|            6.0|14.400000095367432|          124.0|            6.0|           8.96|\n",
      "|A Ahmadhel|Bulgaria|   2023|             9|            8.0| 17.40000009536743|          155.0|            6.0|            9.3|\n",
      "+----------+--------+-------+--------------+---------------+------------------+---------------+---------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bowling_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53489\n",
      "+---------------+-------+------+---------+--------+--------------+---------------+--------------+-------------+-------------+--------------+--------------+---------------+-----------------+---------------+---------------+---------------+-------------+--------------+--------------+---------------+------+\n",
      "|         player|Country|Season|player_id|match_id|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|Cumulative Mat|Cumulative Inns| Cumulative Overs|Cumulative Runs|Cumulative Wkts|Cumulative Econ|Cum Mat Total|Cum Inns Total|Cum Runs Total|Cum Batting Ave|Cum SR|\n",
      "+---------------+-------+------+---------+--------+--------------+---------------+--------------+-------------+-------------+--------------+--------------+---------------+-----------------+---------------+---------------+---------------+-------------+--------------+--------------+---------------+------+\n",
      "|    R Satheesan|Romania|  2022| 1125ebe4| 1310187|            17|           17.0|           8.0|          8.0|          0.0|          0.47|            17|           10.0|             24.0|          119.0|            9.0|           5.63|           17|            15|           550|          46.75|185.29|\n",
      "|Taranjeet Singh|Romania|  2022| ec483176| 1310187|             8|            8.0|           2.0|          2.0|          0.0|          0.25|             8|            8.0|             26.0|          158.0|            9.0|           6.07|            8|             8|           276|          39.42|195.74|\n",
      "|    S Nadigotla|Romania|  2022| b78b3ffd| 1310187|            10|           10.0|          15.0|         10.0|          5.0|           1.5|            10|            1.0|              2.0|           10.0|            0.0|            5.0|           10|             8|           160|          24.19|127.63|\n",
      "|  Abdul Shakoor|Romania|  2022| d52b13a6| 1310187|             8|            8.0|           6.0|          4.0|          2.0|          0.75|             8|            0.0|              0.0|            0.0|            0.0|            0.0|            8|             6|            86|          23.75| 98.36|\n",
      "|        V Saini|Romania|  2022| 0fa81719| 1310187|            12|           12.0|           6.0|          6.0|          0.0|           0.5|            12|           12.0|38.29999923706055|          272.0|           11.0|           7.07|           12|             8|           102|          19.89|140.68|\n",
      "+---------------+-------+------+---------+--------+--------------+---------------+--------------+-------------+-------------+--------------+--------------+---------------+-----------------+---------------+---------------+---------------+-------------+--------------+--------------+---------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_data = players_data.join(fielding_data, ['Player', 'Country', 'Season'], 'inner').join(bowling_data, ['Player', 'Country', 'Season'], 'inner').join(batting_data, ['Player', 'Country', 'Season'], 'inner')\n",
    "player_data = batting_data.join(bowling_data, on=['Player',\"Country\",\"Season\"], how='inner').join(fielding_data, on=['Player',\"Country\",\"Season\"], how='inner')\\\n",
    "                        .drop('Cumulative Mat','Cumulative Inns')\n",
    "print(players_data.count())\n",
    "players_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/15 10:54:51 WARN DataStreamer: Exception for BP-1744012875-127.0.1.1-1731345514466:blk_1073790793_49977\n",
      "java.net.SocketTimeoutException: 65000 millis timeout while waiting for channel to be ready for read. ch : java.nio.channels.SocketChannel[connected local=/192.168.245.142:60464 remote=/192.168.245.142:9866]\n",
      "\tat org.apache.hadoop.net.SocketIOWithTimeout.doIO(SocketIOWithTimeout.java:163)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:161)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:131)\n",
      "\tat org.apache.hadoop.net.SocketInputStream.read(SocketInputStream.java:118)\n",
      "\tat java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat java.base/java.io.FilterInputStream.read(FilterInputStream.java:83)\n",
      "\tat org.apache.hadoop.hdfs.protocolPB.PBHelperClient.vintPrefixed(PBHelperClient.java:519)\n",
      "\tat org.apache.hadoop.hdfs.protocol.datatransfer.PipelineAck.readFields(PipelineAck.java:213)\n",
      "\tat org.apache.hadoop.hdfs.DataStreamer$ResponseProcessor.run(DataStreamer.java:1137)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Combine batting, bowling, and fielding statistics into a single dataset.\"\"\"\n",
    "\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..'))\n",
    "sys.path.append(os.path.join(os.getcwd(), '..'))\n",
    "import config\n",
    "\n",
    "import config\n",
    "from utils import load_data, spark_save_data\n",
    "\n",
    "def combine_data(spark):\n",
    "    \"\"\"Combine batting, bowling, and fielding statistics into a single dataset.\"\"\"\n",
    "    logging.info(\"Starting combine_data task.\")\n",
    "\n",
    "    try:\n",
    "        batting_data = load_data(spark, config.PROCESSED_DATA_DIR, 'batting_data.csv')\n",
    "        bowling_data = load_data(spark, config.PROCESSED_DATA_DIR, 'bowling_data.csv')\n",
    "        fielding_data = load_data(spark, config.PROCESSED_DATA_DIR, 'fielding_data.csv')\n",
    "        players_data = load_data(spark, config.PROCESSED_DATA_DIR, 'match_players.csv').withColumnRenamed(\"country\", \"Country\").withColumnRenamed(\"season\", \"Season\")\n",
    "\n",
    "        batting_data = batting_data.join(players_data, ['Player', 'Country', 'Season'], 'inner')\n",
    "        bowling_data = bowling_data.join(players_data, ['Player', 'Country', 'Season'], 'inner')\n",
    "        fielding_data = fielding_data.join(players_data, ['Player', 'Country', 'Season'], 'inner')\n",
    "\n",
    "        batting_data = batting_data.select(['player_id', 'Player', 'Country', \"Season\",\"Cum Mat Total\", \"Cum Runs Total\", 'Cum SR']).sort(\"Player\",\"Season\")\n",
    "        bowling_data = bowling_data.select(['player_id', 'Player', 'Country', \"Season\",\"Cumulative Mat\", \"Cumulative Inns\", 'Cumulative Overs','Cumulative Runs','Cumulative Wkts','Cumulative Econ']).withColumnRenamed(\"Cumulative Runs\",\"Cumulative Bowling Runs\")\n",
    "        fielding_data = fielding_data.select(['player_id', 'Player', 'Country', \"Season\",\"Cumulative Mat\", \"Cumulative Inns\", 'Cumulative Dis','Cumulative Ct','Cumulative St','Cumulative D/I'])\n",
    "\n",
    "        player_data = batting_data.join(bowling_data, on=['player_id','Player',\"Country\",\"Season\"], how='inner').join(fielding_data, on=['player_id','Player',\"Country\",\"Season\"], how='inner')\\\n",
    "                        .drop('Cumulative Mat','Cumulative Inns')\n",
    "        print(player_data.count())\n",
    "        print(player_data.show(5))\n",
    "        spark_save_data(player_data, config.PROCESSED_DATA_DIR, 'player_stats.csv')\n",
    "        logging.info(\"Data combining and saving completed successfully.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error in combine_data task: {e}\")\n",
    "        raise\n",
    "    finally:\n",
    "        spark.stop()\n",
    "        logging.info(\"Spark session stopped.\")\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t20i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
