{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/ravikumar/miniconda3/envs/t20i/lib/python3.12/site-packages/airflow/configuration.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">859</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> FutureWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: section/key </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">core/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> has been deprecated, you should use</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">database/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> instead. Please update your `conf.get*` call to use the new name</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/ravikumar/miniconda3/envs/t20i/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T13:43:28.445+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m17} INFO\u001b[0m - Creating Spark session.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/11/24 13:43:34 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/24 13:43:36 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T13:43:39.399+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m37} INFO\u001b[0m - Spark session created successfully.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+----+----+---+-----+-----+-----+----+---+---+-------+-----------+\n",
      "|        Team|Mat|Won|Lost|Tied| NR|  W/L|  Ave|  RPO|Inns| HS| LS| Season|Unnamed: 13|\n",
      "+------------+---+---+----+----+---+-----+-----+-----+----+---+---+-------+-----------+\n",
      "|   Australia|  1|  1|   0|   0|  0|    -|42.80| 10.7|   1|214|  -|2004/05|       null|\n",
      "| New Zealand|  1|  0|   1|   0|  0|0.000|17.00|  8.5|   1|170|170|2004/05|       null|\n",
      "|   Australia|  1|  0|   1|   0|  0|0.000| 7.90| 5.44|   1| 79| 79|   2005|       null|\n",
      "|     England|  1|  1|   0|   0|  0|    -|22.37| 8.95|   1|179|  -|   2005|       null|\n",
      "|   Australia|  2|  1|   1|   0|  0|1.000|40.80| 10.2|   2|209|  -|2005/06|       null|\n",
      "| New Zealand|  2|  1|   0|   1|  0|    -|20.00| 6.84|   2|134|  -|2005/06|       null|\n",
      "|South Africa|  3|  1|   2|   0|  0|0.500|18.66| 7.72|   3|201|114|2005/06|       null|\n",
      "| West Indies|  1|  0|   0|   1|  0|0.000|18.00|  6.3|   1|126|  -|2005/06|       null|\n",
      "|     England|  2|  0|   2|   0|  0|0.000|25.41| 7.62|   2|161|  -|   2006|       null|\n",
      "|    Pakistan|  1|  1|   0|   0|  0|    -|29.60| 8.29|   1|148|  -|   2006|       null|\n",
      "|   Sri Lanka|  1|  1|   0|   0|  0|    -|16.30| 8.15|   1|163|163|   2006|       null|\n",
      "|   Australia|  1|  1|   0|   0|  0|    -|44.20|11.05|   1|221|  -|2006/07|       null|\n",
      "|  Bangladesh|  1|  1|   0|   0|  0|    -|16.60| 8.36|   1|166|166|2006/07|       null|\n",
      "|     England|  1|  0|   1|   0|  0|0.000|16.00|  7.2|   1|144|  -|2006/07|       null|\n",
      "|       India|  1|  1|   0|   0|  0|    -|31.75|  6.4|   1|127|  -|2006/07|       null|\n",
      "| New Zealand|  2|  1|   1|   0|  0|1.000|21.38| 7.22|   2|162|  -|2006/07|       null|\n",
      "|    Pakistan|  1|  0|   1|   0|  0|0.000|16.12| 6.45|   1|129|  -|2006/07|       null|\n",
      "|South Africa|  2|  1|   1|   0|  0|1.000|28.66| 8.19|   2|132|  -|2006/07|       null|\n",
      "|   Sri Lanka|  2|  1|   1|   0|  0|1.000|16.09| 7.32|   2|115|115|2006/07|       null|\n",
      "|    Zimbabwe|  1|  0|   1|   0|  0|0.000|13.66| 6.15|   1|123|  -|2006/07|       null|\n",
      "+------------+---+---+----+----+---+-----+-----+-----+----+---+---+-------+-----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..','..'))\n",
    "from configs import spark_config as config\n",
    "from utils import spark_utils as utils\n",
    "\n",
    "# Specify the directory where your CSV files are located\n",
    "directory = config.RAW_DATA_DIR \n",
    "\n",
    "# sparksession\n",
    "spark = utils.create_spark_session(\"T20 Team Stats\")\n",
    "\n",
    "team_data = spark.read.csv(os.path.join(directory, 't20_team_stats.csv'), header=True, inferSchema=True)\n",
    "team_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+---+---+----+----+---+---+----+---+-------+-----------+------+------+\n",
      "|        Team|Mat|Won|Lost|Tied| NR|W/L|Inns| HS| Season|Unnamed: 13|AveRPW|AveRPO|\n",
      "+------------+---+---+----+----+---+---+----+---+-------+-----------+------+------+\n",
      "|   Australia|  1|  1|   0|   0|  0|1.0|   1|214|2004/05|       null|  42.8|  10.7|\n",
      "| New Zealand|  1|  0|   1|   0|  0|0.0|   1|170|2004/05|       null|  17.0|   8.5|\n",
      "|   Australia|  1|  0|   1|   0|  0|0.0|   1| 79|   2005|       null|   7.9|  5.44|\n",
      "|     England|  1|  1|   0|   0|  0|1.0|   1|179|   2005|       null| 22.37|  8.95|\n",
      "|   Australia|  2|  1|   1|   0|  0|1.0|   2|209|2005/06|       null|  40.8|  10.2|\n",
      "| New Zealand|  2|  1|   0|   1|  0|1.0|   2|134|2005/06|       null|  20.0|  6.84|\n",
      "|South Africa|  3|  1|   2|   0|  0|0.5|   3|201|2005/06|       null| 18.66|  7.72|\n",
      "| West Indies|  1|  0|   0|   1|  0|0.0|   1|126|2005/06|       null|  18.0|   6.3|\n",
      "|     England|  2|  0|   2|   0|  0|0.0|   2|161|   2006|       null| 25.41|  7.62|\n",
      "|    Pakistan|  1|  1|   0|   0|  0|1.0|   1|148|   2006|       null|  29.6|  8.29|\n",
      "|   Sri Lanka|  1|  1|   0|   0|  0|1.0|   1|163|   2006|       null|  16.3|  8.15|\n",
      "|   Australia|  1|  1|   0|   0|  0|1.0|   1|221|2006/07|       null|  44.2| 11.05|\n",
      "|  Bangladesh|  1|  1|   0|   0|  0|1.0|   1|166|2006/07|       null|  16.6|  8.36|\n",
      "|     England|  1|  0|   1|   0|  0|0.0|   1|144|2006/07|       null|  16.0|   7.2|\n",
      "|       India|  1|  1|   0|   0|  0|1.0|   1|127|2006/07|       null| 31.75|   6.4|\n",
      "| New Zealand|  2|  1|   1|   0|  0|1.0|   2|162|2006/07|       null| 21.38|  7.22|\n",
      "|    Pakistan|  1|  0|   1|   0|  0|0.0|   1|129|2006/07|       null| 16.12|  6.45|\n",
      "|South Africa|  2|  1|   1|   0|  0|1.0|   2|132|2006/07|       null| 28.66|  8.19|\n",
      "|   Sri Lanka|  2|  1|   1|   0|  0|1.0|   2|115|2006/07|       null| 16.09|  7.32|\n",
      "|    Zimbabwe|  1|  0|   1|   0|  0|0.0|   1|123|2006/07|       null| 13.66|  6.15|\n",
      "+------------+---+---+----+----+---+---+----+---+-------+-----------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,when,round\n",
    "team_data = team_data.withColumn(\"W/L\", round(when(col(\"Lost\")==0, col(\"Won\")).otherwise(col(\"Won\")/col(\"Lost\")),2))\n",
    "team_data = team_data.withColumn(\"AveRPW\", when(col(\"Ave\")=='-',0).otherwise(col(\"Ave\")).cast(\"float\")).drop(\"Ave\")\n",
    "team_data = team_data.withColumn(\"AveRPO\", when(col(\"RPO\")=='-',0).otherwise(col(\"RPO\")).cast(\"float\")).drop(\"RPO\",\"LS\")\n",
    "team_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---+----+----+---+----+----+---+-------+-----------+------+------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "|       Team|Mat|Won|Lost|Tied| NR| W/L|Inns| HS| Season|Unnamed: 13|AveRPW|AveRPO|Cumulative Won|Cumulative Lost|Cumulative Tied|Cumulative NR|Cumulative W/L|Cumulative AveRPW|Cumulative AveRPO|\n",
      "+-----------+---+---+----+----+---+----+----+---+-------+-----------+------+------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "|Afghanistan|  6|  4|   2|   0|  0| 2.0|   6|147|2009/10|       null| 20.22|  6.89|             0|              0|              0|            0|           0.0|              0.0|              0.0|\n",
      "|Afghanistan|  2|  0|   2|   0|  0| 0.0|   2|115|   2010|       null| 10.83|  5.41|             4|              2|              0|            0|           2.0|            20.22|             6.89|\n",
      "|Afghanistan|  3|  2|   1|   0|  0| 2.0|   3|174|2011/12|       null| 22.66|  7.97|             4|              4|              0|            0|           1.0|            17.87|             6.52|\n",
      "|Afghanistan|  4|  2|   2|   0|  0| 1.0|   4|140|2012/13|       null| 16.26|  6.56|             6|              5|              0|            0|           1.2|            19.18|             6.92|\n",
      "|Afghanistan| 10|  4|   6|   0|  0|0.67|  10|171|2013/14|       null| 17.15|  6.92|             8|              7|              0|            0|          1.14|             18.4|             6.82|\n",
      "|Afghanistan|  6|  5|   1|   0|  0| 5.0|   6|210|   2015|       null| 31.96|  8.37|            12|             13|              0|            0|          0.92|             17.9|             6.86|\n",
      "|Afghanistan| 17| 12|   5|   0|  0| 2.4|  17|215|2015/16|       null| 24.85|  8.27|            17|             14|              0|            0|          1.21|            20.62|             7.15|\n",
      "|Afghanistan| 10| 10|   0|   0|  0|10.0|  10|233|2016/17|       null| 33.72|  8.92|            29|             19|              0|            0|          1.53|            22.12|             7.55|\n",
      "|Afghanistan|  3|  0|   3|   0|  0| 0.0|   3|146|   2017|       null| 13.42|  6.52|            39|             19|              0|            0|          2.05|            24.12|             7.78|\n",
      "|Afghanistan|  2|  2|   0|   0|  0| 2.0|   2|158|2017/18|       null| 19.92|  8.04|            39|             22|              0|            0|          1.77|            23.59|             7.72|\n",
      "+-----------+---+---+----+----+---+----+----+---+-------+-----------+------+------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# Cumulative calculations\n",
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when, row_number, round\n",
    "\n",
    "# Define the window specification for cumulative calculations\n",
    "window_spec = Window.partitionBy(\"Team\").orderBy(\"Season\").rowsBetween(Window.unboundedPreceding, -1)\n",
    "\n",
    "# Window for row number to identify the first row per player and country\n",
    "row_num_window = Window.partitionBy(\"Team\").orderBy(\"Season\")\n",
    "\n",
    "# perform cumulative calculations\n",
    "team_data = team_data.withColumn(\"row_num\", row_number().over(row_num_window)) \\\n",
    "    .withColumn(\"Cumulative Won\",\n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(spark_sum(\"Won\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative Lost\",\n",
    "                when(col(\"row_num\") == 1, 0)  # Set 0 for the first row (before any match)\n",
    "                .otherwise(spark_sum(\"Lost\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative Tied\", \n",
    "                when(col(\"row_num\") == 1, 0)  # Set 0 for the first row (before any match)\n",
    "                .otherwise(spark_sum(\"Tied\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative NR\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(spark_sum(\"NR\").over(window_spec))) \\\n",
    "    .withColumn(\"Cumulative W/L\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(\n",
    "                    round(\n",
    "                        when(spark_sum(\"Lost\").over(window_spec) != 0, \n",
    "                             spark_sum((\"Won\")).over(window_spec) / spark_sum(\"Lost\").over(window_spec))\n",
    "                        .otherwise(0), 2)\n",
    "                )\n",
    "    ) \\\n",
    "    .withColumn(\"Cumulative AveRPW\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(\n",
    "                    round(\n",
    "                        when(spark_sum(\"Won\").over(window_spec) != 0, \n",
    "                             spark_sum(col(\"AveRPW\")*col(\"Mat\")).over(window_spec) / spark_sum(\"Mat\").over(window_spec))\n",
    "                        .otherwise(0), 2)\n",
    "                )\n",
    "    ) \\\n",
    "    .withColumn(\"Cumulative AveRPO\", \n",
    "                when(col(\"row_num\") == 1, 0)\n",
    "                .otherwise(\n",
    "                    round(\n",
    "                        when(spark_sum(\"Lost\").over(window_spec) != 0, \n",
    "                             spark_sum(col(\"AveRPO\")*col(\"Mat\")).over(window_spec) / spark_sum(\"Mat\").over(window_spec))\n",
    "                        .otherwise(0), 2)\n",
    "                )\n",
    "    ) \\\n",
    "    .drop(\"row_num\")  # Drop the temporary row number column\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "team_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "|       Team| Season|Cumulative Won|Cumulative Lost|Cumulative Tied|Cumulative NR|Cumulative W/L|Cumulative AveRPW|Cumulative AveRPO|\n",
      "+-----------+-------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "|Afghanistan|2009/10|             0|              0|              0|            0|           0.0|              0.0|              0.0|\n",
      "|Afghanistan|   2010|             4|              2|              0|            0|           2.0|            20.22|             6.89|\n",
      "|Afghanistan|2011/12|             4|              4|              0|            0|           1.0|            17.87|             6.52|\n",
      "|Afghanistan|2012/13|             6|              5|              0|            0|           1.2|            19.18|             6.92|\n",
      "|Afghanistan|2013/14|             8|              7|              0|            0|          1.14|             18.4|             6.82|\n",
      "|Afghanistan|   2015|            12|             13|              0|            0|          0.92|             17.9|             6.86|\n",
      "|Afghanistan|2015/16|            17|             14|              0|            0|          1.21|            20.62|             7.15|\n",
      "|Afghanistan|2016/17|            29|             19|              0|            0|          1.53|            22.12|             7.55|\n",
      "|Afghanistan|   2017|            39|             19|              0|            0|          2.05|            24.12|             7.78|\n",
      "|Afghanistan|2017/18|            39|             22|              0|            0|          1.77|            23.59|             7.72|\n",
      "|Afghanistan|   2018|            41|             22|              0|            0|          1.86|            23.48|             7.73|\n",
      "|Afghanistan|2018/19|            46|             22|              0|            0|          2.09|            23.46|             7.75|\n",
      "|Afghanistan|   2019|            49|             22|              0|            0|          2.23|            24.23|             7.86|\n",
      "|Afghanistan|2019/20|            51|             24|              0|            0|          2.13|            24.27|             7.88|\n",
      "|Afghanistan|2020/21|            55|             25|              1|            0|           2.2|            24.14|             7.87|\n",
      "|Afghanistan|2021/22|            58|             25|              1|            0|          2.32|            24.48|             7.93|\n",
      "|Afghanistan|   2022|            61|             29|              1|            0|           2.1|            24.39|             7.88|\n",
      "|Afghanistan|2022/23|            68|             35|              1|            0|          1.94|            24.45|             7.86|\n",
      "|Afghanistan|   2023|            72|             40|              1|            0|           1.8|             24.2|             7.79|\n",
      "|Afghanistan|2023/24|            74|             42|              1|            1|          1.76|            23.92|             7.74|\n",
      "+-----------+-------+--------------+---------------+---------------+-------------+--------------+-----------------+-----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "team_data = team_data.select(\"Team\", \"Season\",\"Cumulative Won\", \"Cumulative Lost\", \"Cumulative Tied\", \"Cumulative NR\", \"Cumulative W/L\", \"Cumulative AveRPW\", \"Cumulative AveRPO\")\n",
    "team_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "team_data.write.csv(os.path.join(config.PROCESSED_DATA_DIR, 'team_stats.csv'), header=True, mode='overwrite')\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t20i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
