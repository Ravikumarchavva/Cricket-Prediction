{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">/home/ravikumar/miniconda3/envs/t20i/lib/python3.12/site-packages/airflow/configuration.py:</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">859</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> FutureWarning</span><span style=\"color: #808000; text-decoration-color: #808000\">: section/key </span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">core/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> has been deprecated, you should use</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">[</span><span style=\"color: #808000; text-decoration-color: #808000\">database/sql_alchemy_conn</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">]</span><span style=\"color: #808000; text-decoration-color: #808000\"> instead. Please update your `conf.get*` call to use the new name</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;33m/home/ravikumar/miniconda3/envs/t20i/lib/python3.12/site-packages/airflow/\u001b[0m\u001b[1;33mconfiguration.py\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m859\u001b[0m\u001b[1;33m FutureWarning\u001b[0m\u001b[33m: section/key \u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mcore/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m has been deprecated, you should use\u001b[0m\u001b[1;33m[\u001b[0m\u001b[33mdatabase/sql_alchemy_conn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[33m instead. Please update your `conf.get*` call to use the new name\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T14:14:32.688+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m17} INFO\u001b[0m - Creating Spark session.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/11/24 14:14:35 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/11/24 14:14:37 WARN Utils: spark.executor.instances less than spark.dynamicAllocation.minExecutors is invalid, ignoring its setting, please update your configs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T14:14:38.060+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m37} INFO\u001b[0m - Spark session created successfully.\u001b[0m\n",
      "[\u001b[34m2024-11-24T14:14:38.063+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m46} INFO\u001b[0m - Loading data from t20_fielding_stats.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 2:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+---+----+---+---+---+-----+-----+---+---+-------+\n",
      "|            Player|Mat|Inns|Dis| Ct| St|Ct Wk|Ct Fi| MD|D/I| Season|\n",
      "+------------------+---+----+---+---+---+-----+-----+---+---+-------+\n",
      "|     AR Adams (NZ)|  1|   1|  0|  0|  0|    0|    0|  0|0.0|2004/05|\n",
      "|    CL Cairns (NZ)|  1|   1|  0|  0|  0|    0|    0|  0|0.0|2004/05|\n",
      "|   MJ Clarke (AUS)|  1|   1|  0|  0|  0|    0|    0|  0|0.0|2004/05|\n",
      "|   SP Fleming (NZ)|  1|   1|  0|  0|  0|    0|    0|  0|0.0|2004/05|\n",
      "|AC Gilchrist (AUS)|  1|   1|  0|  0|  0|    0|    0|  0|0.0|2004/05|\n",
      "+------------------+---+----+---+---+---+-----+-----+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.join(os.getcwd(), '..','..','..','..'))\n",
    "from configs import spark_config as config\n",
    "from utils import spark_utils as utils\n",
    "\n",
    "# Create a Spark session\n",
    "spark = utils.create_spark_session(\"fielding\", {\n",
    "    'spark.executor.memory': '3g',\n",
    "    'spark.executor.cores': '6',\n",
    "})\n",
    "\n",
    "fielding_data = utils.load_data(spark,config.RAW_DATA_DIR, 't20_fielding_stats.csv')\n",
    "\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "|          Player|Mat|Inns|Dis| Ct| St|  D/I| Season|\n",
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "|A Ahmadhel (BUL)|  3|   3|  0|  0|  0|  0.0|2019/20|\n",
      "|A Ahmadhel (BUL)|  1|   1|  0|  0|  0|0.000|   2020|\n",
      "|A Ahmadhel (BUL)|  2|   2|  0|  0|  0|0.000|2020/21|\n",
      "|A Ahmadhel (BUL)|  3|   3|  0|  0|  0|  0.0|   2021|\n",
      "|A Ahmadhel (BUL)|  2|   1|  0|  0|  0|  0.0|   2023|\n",
      "+----------------+---+----+---+---+---+-----+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.select(['Player',\"Mat\",\"Inns\",\"Dis\",\"Ct\",\"St\",\"D/I\",\"Season\"]).sort([\"Player\",\"Season\"])\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:>                                                          (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---+----+---+---+---+---+-------+\n",
      "|          Player|Mat|Inns|Dis| Ct| St|D/I| Season|\n",
      "+----------------+---+----+---+---+---+---+-------+\n",
      "|A Ahmadhel (BUL)|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|\n",
      "|A Ahmadhel (BUL)|  1| 1.0|0.0|0.0|0.0|0.0|   2020|\n",
      "|A Ahmadhel (BUL)|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|\n",
      "|A Ahmadhel (BUL)|  3| 3.0|0.0|0.0|0.0|0.0|   2021|\n",
      "|A Ahmadhel (BUL)|  2| 1.0|0.0|0.0|0.0|0.0|   2023|\n",
      "+----------------+---+----+---+---+---+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when\n",
    "fielding_data = fielding_data.withColumn('Inns', when(col('Inns') == '-', '0').otherwise(col('Inns')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('Dis', when(col('Dis') == '-', '0').otherwise(col('Dis')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('Ct', when(col('Ct') == '-', '0').otherwise(col('Ct')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('St', when(col('St') == '-', '0').otherwise(col('St')).cast('float'))\n",
    "fielding_data = fielding_data.withColumn('D/I', when(col('D/I') == '-', col('Dis')/col('Inns')).otherwise(col('D/I')).cast('float')).fillna(0)\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "|    Player|Mat|Inns|Dis| Ct| St|D/I| Season|Country|\n",
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|2019/20|    BUL|\n",
      "|A Ahmadhel|  1| 1.0|0.0|0.0|0.0|0.0|   2020|    BUL|\n",
      "|A Ahmadhel|  2| 2.0|0.0|0.0|0.0|0.0|2020/21|    BUL|\n",
      "|A Ahmadhel|  3| 3.0|0.0|0.0|0.0|0.0|   2021|    BUL|\n",
      "|A Ahmadhel|  2| 1.0|0.0|0.0|0.0|0.0|   2023|    BUL|\n",
      "+----------+---+----+---+---+---+---+-------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import regexp_extract, regexp_replace\n",
    "\n",
    "# Extract the country name between '(' and ')'\n",
    "fielding_data = fielding_data.withColumn(\"Country\", regexp_extract(col(\"Player\"), r\"\\((.*?)\\)\", 1))\n",
    "\n",
    "# Extract the player's name before the first '('\n",
    "fielding_data = fielding_data.withColumn(\"Player\", regexp_extract(col(\"Player\"), r\"^(.*?)\\s\\(\", 1))\n",
    "\n",
    "# Show the result\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 15:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|        Player|Mat|Inns|Dis| Ct| St|  D/I| Season|Country|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+--------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|    A Ahmadhel|  3| 3.0|0.0|0.0|0.0|  0.0|2019/20|    BUL|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Ahmadhel|  1| 1.0|0.0|0.0|0.0|  0.0|   2020|    BUL|             3|            3.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Ahmadhel|  2| 2.0|0.0|0.0|0.0|  0.0|2020/21|    BUL|             4|            4.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Ahmadhel|  3| 3.0|0.0|0.0|0.0|  0.0|   2021|    BUL|             6|            6.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Ahmadhel|  2| 1.0|0.0|0.0|0.0|  0.0|   2023|    BUL|             9|            9.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|    A Ahmadhel|  1| 1.0|1.0|1.0|0.0|  1.0|   2024|    BUL|            11|           10.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|       A Amado|  3| 3.0|2.0|2.0|0.0|0.666|   2022|    ISR|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|     A Andrews|  3| 3.0|4.0|4.0|0.0|1.333|2021/22|    SUI|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|     A Andrews|  4| 4.0|3.0|3.0|0.0| 0.75|   2022|    SUI|             3|            3.0|           4.0|          4.0|          0.0|          1.33|\n",
      "|A Anemogiannis|  1| 1.0|0.0|0.0|0.0|  0.0|2019/20|    GRC|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+--------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import col, sum as spark_sum, when, row_number, round\n",
    "\n",
    "# Define the window specification for cumulative calculations\n",
    "window_spec = (\n",
    "    Window.partitionBy(\"Player\", \"Country\")\n",
    "    .orderBy(\"Season\")\n",
    "    .rowsBetween(Window.unboundedPreceding, -1)\n",
    ")\n",
    "\n",
    "# Window for row number to identify the first row per player and country\n",
    "row_num_window = Window.partitionBy(\"Player\", \"Country\").orderBy(\"Season\")\n",
    "\n",
    "# Perform cumulative calculations with conditions\n",
    "fielding_data = (\n",
    "    fielding_data.withColumn(\"row_num\", row_number().over(row_num_window))\n",
    "    .withColumn(\n",
    "        \"Cumulative Mat\",\n",
    "        when(col(\"row_num\") == 1, 0).otherwise(spark_sum(\"Mat\").over(window_spec)),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Cumulative Inns\",\n",
    "        when(\n",
    "            col(\"row_num\") == 1, 0\n",
    "        ).otherwise(  # Set 0 for the first row (before any match)\n",
    "            spark_sum(\"Inns\").over(window_spec)\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Cumulative Dis\",\n",
    "        when(\n",
    "            col(\"row_num\") == 1, 0\n",
    "        ).otherwise(  # Set 0 for the first row (before any match)\n",
    "            spark_sum(\"Dis\").over(window_spec)\n",
    "        ),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Cumulative Ct\",\n",
    "        when(col(\"row_num\") == 1, 0).otherwise(spark_sum(\"Ct\").over(window_spec)),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Cumulative St\",\n",
    "        when(col(\"row_num\") == 1, 0).otherwise(spark_sum(\"St\").over(window_spec)),\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"Cumulative D/I\",\n",
    "        when(col(\"row_num\") == 1, 0).otherwise(\n",
    "            round(\n",
    "                when(\n",
    "                    spark_sum(\"Inns\").over(window_spec) != 0,\n",
    "                    spark_sum((\"Dis\")).over(window_spec)\n",
    "                    / spark_sum(\"Inns\").over(window_spec),\n",
    "                ).otherwise(0),\n",
    "                2,\n",
    "            )\n",
    "        ),\n",
    "    )\n",
    "    .drop(\"row_num\")\n",
    ")  # Drop the temporary row number column\n",
    "\n",
    "# Show the resulting DataFrame\n",
    "fielding_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|         Player|Mat|Inns|Dis| Ct| St|  D/I| Season|Country|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+---------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|Shakib Al Hasan|  1| 1.0|0.0|0.0|0.0|  0.0|2006/07|    BAN|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|Shakib Al Hasan|  6| 6.0|2.0|2.0|0.0|0.333|2007/08|    BAN|             1|            1.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|Shakib Al Hasan|  1| 1.0|1.0|1.0|0.0|  1.0|2008/09|    BAN|             7|            7.0|           2.0|          2.0|          0.0|          0.29|\n",
      "|Shakib Al Hasan|  3| 3.0|1.0|1.0|0.0|0.333|   2009|    BAN|             8|            8.0|           3.0|          3.0|          0.0|          0.38|\n",
      "|Shakib Al Hasan|  1| 1.0|0.0|0.0|0.0|  0.0|2009/10|    BAN|            11|           11.0|           4.0|          4.0|          0.0|          0.36|\n",
      "|Shakib Al Hasan|  2| 2.0|0.0|0.0|0.0|  0.0|   2010|    BAN|            12|           12.0|           4.0|          4.0|          0.0|          0.33|\n",
      "|Shakib Al Hasan|  2| 2.0|0.0|0.0|0.0|  0.0|2011/12|    BAN|            14|           14.0|           4.0|          4.0|          0.0|          0.29|\n",
      "|Shakib Al Hasan|  6| 6.0|2.0|2.0|0.0|0.333|   2012|    BAN|            16|           16.0|           4.0|          4.0|          0.0|          0.25|\n",
      "|Shakib Al Hasan|  2| 2.0|0.0|0.0|0.0|  0.0|2012/13|    BAN|            22|           22.0|           6.0|          6.0|          0.0|          0.27|\n",
      "|Shakib Al Hasan|  2| 2.0|1.0|1.0|0.0|  0.5|   2013|    BAN|            24|           24.0|           6.0|          6.0|          0.0|          0.25|\n",
      "|Shakib Al Hasan|  9| 9.0|2.0|2.0|0.0|0.222|2013/14|    BAN|            26|           26.0|           7.0|          7.0|          0.0|          0.27|\n",
      "|Shakib Al Hasan|  3| 3.0|1.0|1.0|0.0|0.333|   2015|    BAN|            35|           35.0|           9.0|          9.0|          0.0|          0.26|\n",
      "|Shakib Al Hasan| 16|15.0|6.0|6.0|0.0|  0.4|2015/16|    BAN|            38|           38.0|          10.0|         10.0|          0.0|          0.26|\n",
      "|Shakib Al Hasan|  5| 5.0|1.0|1.0|0.0|  0.2|2016/17|    BAN|            54|           53.0|          16.0|         16.0|          0.0|           0.3|\n",
      "|Shakib Al Hasan|  4| 4.0|0.0|0.0|0.0|  0.0|2017/18|    BAN|            59|           58.0|          17.0|         17.0|          0.0|          0.29|\n",
      "|Shakib Al Hasan|  6| 6.0|1.0|1.0|0.0|0.166|   2018|    BAN|            63|           62.0|          17.0|         17.0|          0.0|          0.27|\n",
      "|Shakib Al Hasan|  3| 3.0|0.0|0.0|0.0|  0.0|2018/19|    BAN|            69|           68.0|          18.0|         18.0|          0.0|          0.26|\n",
      "|Shakib Al Hasan|  4| 4.0|1.0|1.0|0.0| 0.25|   2019|    BAN|            72|           71.0|          18.0|         18.0|          0.0|          0.25|\n",
      "|Shakib Al Hasan| 12|12.0|2.0|2.0|0.0|0.166|   2021|    BAN|            76|           75.0|          19.0|         19.0|          0.0|          0.25|\n",
      "|Shakib Al Hasan|  8| 8.0|1.0|1.0|0.0|0.125|2021/22|    BAN|            88|           87.0|          21.0|         21.0|          0.0|          0.24|\n",
      "+---------------+---+----+---+---+---+-----+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data.filter(col(\"Player\") == \"Shakib Al Hasan\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|    Player|Country| Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|    BUL|2019/20|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2020|             3|            3.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|2020/21|             4|            4.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2021|             6|            6.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2023|             9|            9.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.select(['Player', 'Country', 'Season', 'Cumulative Mat', 'Cumulative Inns', 'Cumulative Dis', 'Cumulative Ct', 'Cumulative St', 'Cumulative D/I'])\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|Player|Country|Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+------+-------+------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|     0|      0|     0|             0|              0|             0|            0|            0|             0|\n",
      "+------+-------+------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# calculate null count\n",
    "from pyspark.sql.functions import isnan, when, count\n",
    "\n",
    "fielding_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in fielding_data.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(103, 11, 5, 103)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "country_codes = {\n",
    "    'LES': 'Lesotho',\n",
    "    'BUL': 'Bulgaria',\n",
    "    'VAN': 'Vanuatu',\n",
    "    'ROM': 'Romania',\n",
    "    'Aut': 'Austria',\n",
    "    'COK': 'Cook Islands',\n",
    "    'Fran': 'France',\n",
    "    'SRB': 'Serbia',\n",
    "    'PAK': 'Pakistan',\n",
    "    'HUN': 'Hungary',\n",
    "    'CYP': 'Cyprus',\n",
    "    'Fiji': 'Fiji',\n",
    "    'FIN': 'Finland',\n",
    "    'EST': 'Estonia',\n",
    "    'CHN': 'China',\n",
    "    'GRC': 'Greece',\n",
    "    'CAM': 'Cambodia',\n",
    "    'GUE': 'Guernsey',\n",
    "    'SEY': 'Seychelles',\n",
    "    'JPN': 'Japan',\n",
    "    'TAN': 'Tanzania',\n",
    "    'JER': 'Jersey',\n",
    "    'QAT': 'Qatar',\n",
    "    'ENG': 'England',\n",
    "    'UGA': 'Uganda',\n",
    "    'BER': 'Bermuda',\n",
    "    'CZK-R': 'Czech Republic',\n",
    "    'CAY': 'Cayman Islands',\n",
    "    'IRE': 'Ireland',\n",
    "    'Mali': 'Mali',\n",
    "    'BRA': 'Brazil',\n",
    "    'SUI': 'Switzerland',\n",
    "    'Peru': 'Peru',\n",
    "    'Mex': 'Mexico',\n",
    "    'MOZ': 'Mozambique',\n",
    "    'Samoa': 'Samoa',\n",
    "    'HKG': 'Hong Kong',\n",
    "    'BAN': 'Bangladesh',\n",
    "    'SL': 'Sri Lanka',\n",
    "    'PNG': 'Papua New Guinea',\n",
    "    'ZIM': 'Zimbabwe',\n",
    "    'GHA': 'Ghana',\n",
    "    'SWZ': 'Eswatini',  # Swaziland's official name now is Eswatini\n",
    "    'MYAN': 'Myanmar',\n",
    "    'IND': 'India',\n",
    "    'USA': 'United States of America',\n",
    "    'NEP': 'Nepal',\n",
    "    'AFG': 'Afghanistan',\n",
    "    'PAN': 'Panama',\n",
    "    'NGA': 'Nigeria',\n",
    "    'SLE': 'Sierra Leone',\n",
    "    'ESP': 'Spain',\n",
    "    'Bhm': 'Bahamas',\n",
    "    'TKY': 'Turkey',\n",
    "    'MWI': 'Malawi',\n",
    "    'WI': 'West Indies',\n",
    "    'IOM': 'Isle of Man',\n",
    "    'THA': 'Thailand',\n",
    "    'SWA': 'Eswatini',  # another code for Eswatini\n",
    "    'SKOR': 'South Korea',\n",
    "    'GMB': 'Gambia',\n",
    "    'ISR': 'Israel',\n",
    "    'KUW': 'Kuwait',\n",
    "    'Belg': 'Belgium',\n",
    "    'GER': 'Germany',\n",
    "    'ITA': 'Italy',\n",
    "    'CAN': 'Canada',\n",
    "    'MDV': 'Maldives',\n",
    "    'Blz': 'Belize',\n",
    "    'DEN': 'Denmark',\n",
    "    'INA': 'Indonesia',\n",
    "    'KENYA': 'Kenya',\n",
    "    'LUX': 'Luxembourg',\n",
    "    'STHEL': 'Saint Helena',\n",
    "    'BHR': 'Bahrain',\n",
    "    'KSA': 'Saudi Arabia',\n",
    "    'MLT': 'Malta',\n",
    "    'Arg': 'Argentina',\n",
    "    'MNG': 'Mongolia',\n",
    "    'AUS': 'Australia',\n",
    "    'GIBR': 'Gibraltar',\n",
    "    'SGP': 'Singapore',\n",
    "    'Chile': 'Chile',\n",
    "    'UAE': 'United Arab Emirates',\n",
    "    'NZ': 'New Zealand',\n",
    "    'SCOT': 'Scotland',\n",
    "    'BHU': 'Bhutan',\n",
    "    'MAS': 'Malaysia',\n",
    "    'BOT': 'Botswana',\n",
    "    'CRC': 'Costa Rica',\n",
    "    'PHI': 'Philippines',\n",
    "    'NAM': 'Namibia',\n",
    "    'RWN': 'Rwanda',\n",
    "    'OMA': 'Oman',\n",
    "    'NOR': 'Norway',\n",
    "    'CRT': 'Croatia',\n",
    "    'SWE': 'Sweden',\n",
    "    'Iran': 'Iran',\n",
    "    'PORT': 'Portugal',\n",
    "    'NED': 'Netherlands',\n",
    "    'SA': 'South Africa',\n",
    "    'SVN': 'Slovenia',\n",
    "    'GUE': 'Guernsey',\n",
    "    'MDV': 'Maldives',\n",
    "    'BHM': 'Bahamas',\n",
    "    'SWE': 'Sweden',\n",
    "    'MLT': 'Malta',\n",
    "    'ITA': 'Italy',\n",
    "}\n",
    "\n",
    "# ICC and World teams\n",
    "icc_world = {\n",
    "    'ICC/PAK': 'Pakistan',\n",
    "    'ICC/SL': 'Sri Lanka',\n",
    "    'ICC/IND': 'India',\n",
    "    'ICC/NEP': 'Nepal',\n",
    "    'BAN/ICC': 'Bangladesh',\n",
    "    'AFG/ICC': 'Afghanistan',\n",
    "    'SL/World': 'Sri Lanka',\n",
    "    'SA/World': 'South Africa',\n",
    "    'AUS/World': 'Australia',\n",
    "    'BAN/World': 'Bangladesh',\n",
    "    'WI/World': 'West Indies',\n",
    "}\n",
    "\n",
    "# Outlier/Miscellaneous Countries\n",
    "outlier_countries = {\n",
    "    '1': 'Miscellaneous Country 1',\n",
    "    '2': 'Miscellaneous Country 2',\n",
    "    '3': 'Miscellaneous Country 3',\n",
    "    'ICC': 'International Cricket Council',\n",
    "    'World': 'World XI',\n",
    "}\n",
    "\n",
    "# Filtered country codes excluding ICC, World teams, and miscellaneous\n",
    "filtered_countries = {\n",
    "    code: country\n",
    "    for code, country in country_codes.items()\n",
    "    if code not in icc_world and code not in outlier_countries\n",
    "}\n",
    "len(country_codes), len(icc_world), len(outlier_countries), len(filtered_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|    Player|Country| Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|    BUL|2019/20|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2020|             3|            3.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|2020/21|             4|            4.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2021|             6|            6.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|    BUL|   2023|             9|            9.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+-------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.filter(col('Country').isin(list(filtered_countries.keys())))\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|    Player| Country| Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|A Ahmadhel|Bulgaria|2019/20|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2020|             3|            3.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|2020/21|             4|            4.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2021|             6|            6.0|           0.0|          0.0|          0.0|           0.0|\n",
      "|A Ahmadhel|Bulgaria|   2023|             9|            9.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+----------+--------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.replace(filtered_countries,subset=['Country'])\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4156, 4101, 14261)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fielding_data[['Player','Country']].distinct().count(), fielding_data[['Player']].distinct().count(), fielding_data.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T14:15:09.038+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m46} INFO\u001b[0m - Loading data from match_players.csv.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19449\n",
      "+---------+---------------+---------+-------+--------+\n",
      "|  Country|         Player|player_id| Season|match_id|\n",
      "+---------+---------------+---------+-------+--------+\n",
      "|Australia|       AJ Finch| b8d490fd|2016/17| 1001349|\n",
      "|Australia|      M Klinger| b970a03f|2016/17| 1001349|\n",
      "|Australia|        TM Head| 12b610c2|2016/17| 1001349|\n",
      "|Australia|   MC Henriques| 32198ae0|2016/17| 1001349|\n",
      "|Australia|      AJ Turner| ff1e12a0|2016/17| 1001349|\n",
      "|Australia|    JP Faulkner| 808f425a|2016/17| 1001349|\n",
      "|Australia|       TD Paine| 5748e866|2016/17| 1001349|\n",
      "|Australia|     PJ Cummins| ded9240e|2016/17| 1001349|\n",
      "|Australia|        A Zampa| 14f96089|2016/17| 1001349|\n",
      "|Australia|     B Stanlake| 6834d1f2|2016/17| 1001349|\n",
      "|Australia|         AJ Tye| 7c7d63a2|2016/17| 1001349|\n",
      "|Sri Lanka|    N Dickwella| 45963d9e|2016/17| 1001349|\n",
      "|Sri Lanka|    WU Tharanga| 7ed9fd56|2016/17| 1001349|\n",
      "|Sri Lanka| EMDY Munaweera| 5a22d91c|2016/17| 1001349|\n",
      "|Sri Lanka|  DAS Gunaratne| 770494eb|2016/17| 1001349|\n",
      "|Sri Lanka|TAM Siriwardana| bf7842c9|2016/17| 1001349|\n",
      "|Sri Lanka|  CK Kapugedera| cfad138c|2016/17| 1001349|\n",
      "|Sri Lanka|     S Prasanna| f78e7113|2016/17| 1001349|\n",
      "|Sri Lanka|  JRMVB Sanjaya| 530b20e3|2016/17| 1001349|\n",
      "|Sri Lanka|     SL Malinga| a12e1d51|2016/17| 1001349|\n",
      "+---------+---------------+---------+-------+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "players_data = utils.load_data(spark,config.PROCESSED_DATA_DIR,'match_players.csv')\n",
    "players_data = players_data.withColumnRenamed(\"player\", \"Player\").withColumnRenamed(\"country\", \"Country\").withColumnRenamed(\"season\", \"Season\")\n",
    "print(players_data[['Player',\"Country\",\"Season\"]].distinct().count())\n",
    "players_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------+---------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "|player_id|      Player|  Country| Season|Cumulative Mat|Cumulative Inns|Cumulative Dis|Cumulative Ct|Cumulative St|Cumulative D/I|\n",
      "+---------+------------+---------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "| b8d490fd|    AJ Finch|Australia|2016/17|            28|           28.0|           7.0|          7.0|          0.0|          0.25|\n",
      "| b970a03f|   M Klinger|Australia|2016/17|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "| 12b610c2|     TM Head|Australia|2016/17|             4|            4.0|           2.0|          2.0|          0.0|           0.5|\n",
      "| 32198ae0|MC Henriques|Australia|2016/17|             6|            6.0|           2.0|          2.0|          0.0|          0.33|\n",
      "| ff1e12a0|   AJ Turner|Australia|2016/17|             0|            0.0|           0.0|          0.0|          0.0|           0.0|\n",
      "+---------+------------+---------+-------+--------------+---------------+--------------+-------------+-------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fielding_data = fielding_data.join(players_data, ['Player', 'Country', \"Season\"], 'inner')\n",
    "fielding_data = fielding_data.select(['player_id', 'Player', 'Country', \"Season\",\"Cumulative Mat\", \"Cumulative Inns\", 'Cumulative Dis','Cumulative Ct','Cumulative St','Cumulative D/I'])\n",
    "print(fielding_data.count())\n",
    "fielding_data.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3586, 3543, 12096)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fielding_data[['Player','Country']].distinct().count(), fielding_data[['Player']].distinct().count(), fielding_data[['Player','Country',\"Season\"]].distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\u001b[34m2024-11-24T14:15:25.208+0530\u001b[0m] {\u001b[34mspark_utils.py:\u001b[0m64} INFO\u001b[0m - Successfully wrote data to /usr/ravi/t20/data/2_processedData/fielding_data.csv\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "utils.spark_save_data(fielding_data, config.PROCESSED_DATA_DIR, 'fielding_data.csv')\n",
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "t20i",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
